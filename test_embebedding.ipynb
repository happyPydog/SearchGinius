{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "VECTORE_PATH = \"./vector_store\"\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "db = FAISS.load_local(folder_path=VECTORE_PATH, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'39296b55-ffea-4268-aec0-d19adc7accb9': Document(page_content='Python custom exception class with a default error message.', metadata={'file_path': PosixPath('MetaGPT/metagpt/config.py'), 'class_name': 'NotConfiguredException', 'summary': 'This source code defines a custom exception class called `NotConfiguredException`. It is used to raise errors related to configuration issues. The class has an optional constructor argument for specifying a custom error message.', 'code': 'class NotConfiguredException(Exception):\\n    \"\"\"Exception raised for errors in the configuration.\\n\\n    Attributes:\\n        message -- explanation of the error\\n    \"\"\"\\n\\n    def __init__(self, message=\"The required configuration is not set\"):\\n        self.message = message\\n        super().__init__(self.message)\\n'}),\n",
       " '60f2cf01-9fc4-4ca4-8ab6-bdb5d43277af': Document(page_content='Python Config Class with Singleton Metaclass', metadata={'file_path': PosixPath('MetaGPT/metagpt/config.py'), 'class_name': 'Config', 'summary': 'This source code defines a Python class called `Config` that is implemented as a singleton. It loads configuration values from YAML files and environment variables, prioritizing the YAML files. It provides methods to retrieve specific configuration values and throws an error if a requested key is not found.', 'code': 'class Config(metaclass=Singleton):\\n    \"\"\"\\n    常规使用方法：\\n    config = Config(\"config.yaml\")\\n    secret_key = config.get_key(\"MY_SECRET_KEY\")\\n    print(\"Secret key:\", secret_key)\\n    \"\"\"\\n\\n    _instance = None\\n    key_yaml_file = PROJECT_ROOT / \"config/key.yaml\"\\n    default_yaml_file = PROJECT_ROOT / \"config/config.yaml\"\\n\\n    def __init__(self, yaml_file=default_yaml_file):\\n        self._configs = {}\\n        self._init_with_config_files_and_env(self._configs, yaml_file)\\n        logger.info(\"Config loading done.\")\\n        self.global_proxy = self._get(\"GLOBAL_PROXY\")\\n        self.openai_api_key = self._get(\"OPENAI_API_KEY\")\\n        if not self.openai_api_key or \"YOUR_API_KEY\" == self.openai_api_key:\\n            raise NotConfiguredException(\"Set OPENAI_API_KEY first\")\\n\\n        self.openai_api_base = self._get(\"OPENAI_API_BASE\")\\n        if not self.openai_api_base or \"YOUR_API_BASE\" == self.openai_api_base:\\n            openai_proxy = self._get(\"OPENAI_PROXY\") or self.global_proxy\\n            if openai_proxy:\\n                openai.proxy = openai_proxy\\n            else:\\n                logger.info(\"Set OPENAI_API_BASE in case of network issues\")\\n        self.openai_api_type = self._get(\"OPENAI_API_TYPE\")\\n        self.openai_api_version = self._get(\"OPENAI_API_VERSION\")\\n        self.openai_api_rpm = self._get(\"RPM\", 3)\\n        self.openai_api_model = self._get(\"OPENAI_API_MODEL\", \"gpt-4\")\\n        self.max_tokens_rsp = self._get(\"MAX_TOKENS\", 2048)\\n        self.deployment_id = self._get(\"DEPLOYMENT_ID\")\\n\\n        self.claude_api_key = self._get(\\'Anthropic_API_KEY\\')\\n        self.serpapi_api_key = self._get(\"SERPAPI_API_KEY\")\\n        self.serper_api_key = self._get(\"SERPER_API_KEY\")\\n        self.google_api_key = self._get(\"GOOGLE_API_KEY\")\\n        self.google_cse_id = self._get(\"GOOGLE_CSE_ID\")\\n        self.search_engine = self._get(\"SEARCH_ENGINE\", SearchEngineType.SERPAPI_GOOGLE)\\n \\n        self.web_browser_engine = WebBrowserEngineType(self._get(\"WEB_BROWSER_ENGINE\", \"playwright\"))\\n        self.playwright_browser_type = self._get(\"PLAYWRIGHT_BROWSER_TYPE\", \"chromium\")\\n        self.selenium_browser_type = self._get(\"SELENIUM_BROWSER_TYPE\", \"chrome\")\\n      \\n        self.long_term_memory = self._get(\\'LONG_TERM_MEMORY\\', False)\\n        if self.long_term_memory:\\n            logger.warning(\"LONG_TERM_MEMORY is True\")\\n        self.max_budget = self._get(\"MAX_BUDGET\", 10.0)\\n        self.total_cost = 0.0\\n        self.puppeteer_config = self._get(\"PUPPETEER_CONFIG\",\"\")\\n        self.mmdc = self._get(\"MMDC\",\"mmdc\")\\n        self.update_costs = self._get(\"UPDATE_COSTS\",True)\\n        self.calc_usage = self._get(\"CALC_USAGE\",True)\\n\\n        \\n\\n    def _init_with_config_files_and_env(self, configs: dict, yaml_file):\\n        \"\"\"从config/key.yaml / config/config.yaml / env三处按优先级递减加载\"\"\"\\n        configs.update(os.environ)\\n\\n        for _yaml_file in [yaml_file, self.key_yaml_file]:\\n            if not _yaml_file.exists():\\n                continue\\n\\n            # 加载本地 YAML 文件\\n            with open(_yaml_file, \"r\", encoding=\"utf-8\") as file:\\n                yaml_data = yaml.safe_load(file)\\n                if not yaml_data:\\n                    continue\\n                os.environ.update({k: v for k, v in yaml_data.items() if isinstance(v, str)})\\n                configs.update(yaml_data)\\n\\n    def _get(self, *args, **kwargs):\\n        return self._configs.get(*args, **kwargs)\\n\\n    def get(self, key, *args, **kwargs):\\n        \"\"\"从config/key.yaml / config/config.yaml / env三处找值，找不到报错\"\"\"\\n        value = self._get(key, *args, **kwargs)\\n        if value is None:\\n            raise ValueError(f\"Key \\'{key}\\' not found in environment variables or in the YAML file\")\\n        return value\\n'}),\n",
       " '12cef067-6463-47bd-be7f-6047db09ecab': Document(page_content='SoftwareCompany class with methods for hiring, investing, starting a project, and running the company.', metadata={'file_path': PosixPath('MetaGPT/metagpt/software_company.py'), 'class_name': 'SoftwareCompany', 'summary': \"This source code defines a class called `SoftwareCompany` which represents a software company. It has attributes such as `environment`, `investment`, and `idea`, and methods like `hire`, `invest`, `start_project`, and `run`. The `run` method runs the company for a specified number of rounds, while the other methods handle tasks like hiring, investing, starting a project, and checking the company's balance.\", 'code': 'class SoftwareCompany(BaseModel):\\n    \"\"\"\\n    Software Company: Possesses a team, SOP (Standard Operating Procedures), and a platform for instant messaging,\\n    dedicated to writing executable code.\\n    \"\"\"\\n    environment: Environment = Field(default_factory=Environment)\\n    investment: float = Field(default=10.0)\\n    idea: str = Field(default=\"\")\\n\\n    class Config:\\n        arbitrary_types_allowed = True\\n\\n    def hire(self, roles: list[Role]):\\n        \"\"\"Hire roles to cooperate\"\"\"\\n        self.environment.add_roles(roles)\\n\\n    def invest(self, investment: float):\\n        \"\"\"Invest company. raise NoMoneyException when exceed max_budget.\"\"\"\\n        self.investment = investment\\n        CONFIG.max_budget = investment\\n        logger.info(f\\'Investment: ${investment}.\\')\\n\\n    def _check_balance(self):\\n        if CONFIG.total_cost > CONFIG.max_budget:\\n            raise NoMoneyException(CONFIG.total_cost, f\\'Insufficient funds: {CONFIG.max_budget}\\')\\n\\n    def start_project(self, idea):\\n        \"\"\"Start a project from publishing boss requirement.\"\"\"\\n        self.idea = idea\\n        self.environment.publish_message(Message(role=\"BOSS\", content=idea, cause_by=BossRequirement))\\n\\n    def _save(self):\\n        logger.info(self.json())\\n\\n    async def run(self, n_round=3):\\n        \"\"\"Run company until target round or no money\"\"\"\\n        while n_round > 0:\\n            # self._save()\\n            n_round -= 1\\n            logger.debug(f\"{n_round=}\")\\n            self._check_balance()\\n            await self.environment.run()\\n        return self.environment.history'}),\n",
       " 'd936048b-40bf-40a8-9123-af46dbafb13a': Document(page_content='class Environment: Class representing an environment that hosts a collection of roles, where roles can send messages to the environment and can be observed by other roles.', metadata={'file_path': PosixPath('MetaGPT/metagpt/environment.py'), 'class_name': 'Environment', 'summary': 'The given source code defines a class called `Environment` that represents an environment for holding a group of roles. Roles can publish messages to the environment, which can be observed by other roles. The environment has methods for adding roles, publishing messages, running roles, and retrieving roles.', 'code': 'class Environment(BaseModel):\\n    \"\"\"环境，承载一批角色，角色可以向环境发布消息，可以被其他角色观察到\"\"\"\\n\\n    roles: dict[str, Role] = Field(default_factory=dict)\\n    memory: Memory = Field(default_factory=Memory)\\n    history: str = Field(default=\\'\\')\\n\\n    class Config:\\n        arbitrary_types_allowed = True\\n\\n    def add_role(self, role: Role):\\n        \"\"\"增加一个在当前环境的Role\"\"\"\\n        role.set_env(self)\\n        self.roles[role.profile] = role\\n\\n    def add_roles(self, roles: Iterable[Role]):\\n        \"\"\"增加一批在当前环境的Role\"\"\"\\n        for role in roles:\\n            self.add_role(role)\\n\\n    def publish_message(self, message: Message):\\n        \"\"\"向当前环境发布信息\"\"\"\\n        # self.message_queue.put(message)\\n        self.memory.add(message)\\n        self.history += f\"\\\\n{message}\"\\n\\n    async def run(self, k=1):\\n        \"\"\"处理一次所有Role的运行\"\"\"\\n        # while not self.message_queue.empty():\\n        # message = self.message_queue.get()\\n        # rsp = await self.manager.handle(message, self)\\n        # self.message_queue.put(rsp)\\n        for _ in range(k):\\n            futures = []\\n            for role in self.roles.values():\\n                future = role.run()\\n                futures.append(future)\\n\\n            await asyncio.gather(*futures)\\n\\n    def get_roles(self) -> dict[str, Role]:\\n        \"\"\"获得环境内的所有Role\"\"\"\\n        return self.roles\\n\\n    def get_role(self, name: str) -> Role:\\n        \"\"\"获得环境内的指定Role\"\"\"\\n        return self.roles.get(name, None)'}),\n",
       " '28f1ade2-d97b-403b-bdb6-6116a090d32f': Document(page_content='Code for handling message routing based on roles', metadata={'file_path': PosixPath('MetaGPT/metagpt/manager.py'), 'class_name': 'Manager', 'summary': 'This source code defines a `Manager` class that handles messages by passing them on to the next role in a predefined direction. It uses a `role_directions` dictionary to determine the next role based on the current role. The `handle` method takes a message and an environment as input, gets all roles from the environment, and then finds the next role based on the current role and the `role_directions`. Finally, it calls the `handle` method of the next role to handle the message.', 'code': 'class Manager:\\n    def __init__(self, llm: LLM = LLM()):\\n        self.llm = llm  # Large Language Model\\n        self.role_directions = {\\n            \"BOSS\": \"Product Manager\",\\n            \"Product Manager\": \"Architect\",\\n            \"Architect\": \"Engineer\",\\n            \"Engineer\": \"QA Engineer\",\\n            \"QA Engineer\": \"Product Manager\"\\n        }\\n        self.prompt_template = \"\"\"\\n        Given the following message:\\n        {message}\\n\\n        And the current status of roles:\\n        {roles}\\n\\n        Which role should handle this message?\\n        \"\"\"\\n\\n    async def handle(self, message: Message, environment):\\n        \"\"\"\\n        管理员处理信息，现在简单的将信息递交给下一个人\\n        :param message:\\n        :param environment:\\n        :return:\\n        \"\"\"\\n        # Get all roles from the environment\\n        roles = environment.get_roles()\\n        # logger.debug(f\"{roles=}, {message=}\")\\n\\n        # Build a context for the LLM to understand the situation\\n        # context = {\\n        #     \"message\": str(message),\\n        #     \"roles\": {role.name: role.get_info() for role in roles},\\n        # }\\n        # Ask the LLM to decide which role should handle the message\\n        # chosen_role_name = self.llm.ask(self.prompt_template.format(context))\\n\\n        # FIXME: 现在通过简单的字典决定流向，但之后还是应该有思考过程\\n        next_role_profile = self.role_directions[message.role]\\n        # logger.debug(f\"{next_role_profile}\")\\n        for _, role in roles.items():\\n            if next_role_profile == role.profile:\\n                next_role = role\\n                break\\n        else:\\n            logger.error(f\"No available role can handle message: {message}.\")\\n            return\\n\\n        # Find the chosen role and handle the message\\n        return await next_role.handle(message)'}),\n",
       " '5a75b7a9-559c-4221-88e7-a6e9ff51e91d': Document(page_content='Python class definition for a raw message structure with content and role attributes.', metadata={'file_path': PosixPath('MetaGPT/metagpt/schema.py'), 'class_name': 'RawMessage', 'summary': 'The code defines a data structure called `RawMessage` using the `TypedDict` class from the `typing` module in Python. It has two fields: `content` of type `str`, and `role` of type `str`. This class can be used to store raw messages with their content and role information.', 'code': 'class RawMessage(TypedDict):\\n    content: str\\n    role: str\\n'}),\n",
       " 'a1d1294c-dd89-4d85-b2e7-d16f17c0a182': Document(page_content='Python class for representing a message, with attributes for content, instruct_content, role, and cause_by. Includes methods for string representation and conversion to dictionary format.', metadata={'file_path': PosixPath('MetaGPT/metagpt/schema.py'), 'class_name': 'Message', 'summary': 'This is a class named \"Message\" with attributes such as content, instruct_content, role, and cause_by. It has methods like __str__ for string representation, __repr__ for debugging purposes, and to_dict for converting the object to a dictionary. The class is used to create message objects with role and content values.', 'code': 'class Message:\\n    \"\"\"list[<role>: <content>]\"\"\"\\n    content: str\\n    instruct_content: BaseModel = field(default=None)\\n    role: str = field(default=\\'user\\')  # system / user / assistant\\n    cause_by: Type[\"Action\"] = field(default=\"\")\\n\\n    def __str__(self):\\n        # prefix = \\'-\\'.join([self.role, str(self.cause_by)])\\n        return f\"{self.role}: {self.content}\"\\n\\n    def __repr__(self):\\n        return self.__str__()\\n\\n    def to_dict(self) -> dict:\\n        return {\\n            \"role\": self.role,\\n            \"content\": self.content\\n        }\\n'}),\n",
       " '9eae6852-c13a-4164-b5e9-462602ba8202': Document(page_content='Class definition for a user message inheriting from the `Message` class.', metadata={'file_path': PosixPath('MetaGPT/metagpt/schema.py'), 'class_name': 'UserMessage', 'summary': \"This source code defines a class called `UserMessage` that inherits from a class called `Message`. The `UserMessage` class has an `__init__` method that takes a `content` parameter of type `str` and calls the `__init__` method of the parent class `Message` with the `content` parameter and a string `'user'`.\", 'code': 'class UserMessage(Message):\\n    \"\"\"便于支持OpenAI的消息\"\"\"\\n    def __init__(self, content: str):\\n        super().__init__(content, \\'user\\')\\n'}),\n",
       " '2fc73427-54aa-4f3b-8d53-d592f8f46af0': Document(page_content='Python class for system messages that support OpenAI.', metadata={'file_path': PosixPath('MetaGPT/metagpt/schema.py'), 'class_name': 'SystemMessage', 'summary': \"This is a class definition for `SystemMessage` that inherits from `Message`. \\nThe purpose of this class is to support messages for OpenAI. \\nIt has an `__init__` method that takes a string parameter `content` and calls the parent class's `__init__` method with the content and 'system' as arguments.\", 'code': 'class SystemMessage(Message):\\n    \"\"\"便于支持OpenAI的消息\"\"\"\\n    def __init__(self, content: str):\\n        super().__init__(content, \\'system\\')\\n'}),\n",
       " '835516b8-308c-4c03-8304-f555b4e57473': Document(page_content='Python class for creating AIMessages with OpenAI support', metadata={'file_path': PosixPath('MetaGPT/metagpt/schema.py'), 'class_name': 'AIMessage', 'summary': \"The code defines a new class called AIMessage that inherits from the Message class. The AIMessage class is specifically designed to support OpenAI messaging. It has an __init__ method that takes a content argument of type str and passes it along with the 'assistant' identifier to the parent class.\", 'code': 'class AIMessage(Message):\\n    \"\"\"便于支持OpenAI的消息\"\"\"\\n    def __init__(self, content: str):\\n        super().__init__(content, \\'assistant\\')\\n'}),\n",
       " '171c74da-1859-4411-876c-6d957804c9d4': Document(page_content='Python class for representing a data source with a name and URL.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/search_engine_meilisearch.py'), 'class_name': 'DataSource', 'summary': 'The code defines a class called `DataSource` with an `__init__` method. \\nThis method takes two arguments, `name` and `url`, and assigns them to instance variables.\\nThe purpose of this class seems to be to create instances for different data sources with a name and a URL.', 'code': 'class DataSource:\\n    def __init__(self, name: str, url: str):\\n        self.name = name\\n        self.url = url\\n'}),\n",
       " 'bc965ae2-258c-47a1-9713-aa9fb41a682f': Document(page_content='MeilisearchEngine class for adding documents and performing search operations', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/search_engine_meilisearch.py'), 'class_name': 'MeilisearchEngine', 'summary': 'This source code defines a class called `MeilisearchEngine` which can be used to interact with the MeiliSearch search engine. It has methods to set the index, add documents to the index, and perform a search on the index. If there is an error while communicating with the MeiliSearch API, it will be caught and handled by printing an error message.', 'code': 'class MeilisearchEngine:\\n    def __init__(self, url, token):\\n        self.client = meilisearch.Client(url, token)\\n        self._index: Index = None\\n\\n    def set_index(self, index):\\n        self._index = index\\n\\n    def add_documents(self, data_source: DataSource, documents: List[dict]):\\n        index_name = f\"{data_source.name}_index\"\\n        if index_name not in self.client.get_indexes():\\n            self.client.create_index(uid=index_name, options={\\'primaryKey\\': \\'id\\'})\\n        index = self.client.get_index(index_name)\\n        index.add_documents(documents)\\n        self.set_index(index)\\n\\n    def search(self, query):\\n        try:\\n            search_results = self._index.search(query)\\n            return search_results[\\'hits\\']\\n        except Exception as e:\\n            # 处理MeiliSearch API错误\\n            print(f\"MeiliSearch API错误: {e}\")\\n            return []'}),\n",
       " 'b212d215-b972-49b7-95c0-860aac86ec4c': Document(page_content='Python class for wrapping the SerpAPI and performing queries on the API.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/search_engine_serpapi.py'), 'class_name': 'SerpAPIWrapper', 'summary': 'This source code defines a Python class called `SerpAPIWrapper` that acts as a wrapper around the SerpAPI. It provides methods to run queries through SerpAPI and process the results. It uses the `google-search-results` python package and requires an API key to be set as an environment variable or passed as a parameter to the constructor.', 'code': 'class SerpAPIWrapper(BaseModel):\\n    \"\"\"Wrapper around SerpAPI.\\n\\n    To use, you should have the ``google-search-results`` python package installed,\\n    and the environment variable ``SERPAPI_API_KEY`` set with your API key, or pass\\n    `serpapi_api_key` as a named parameter to the constructor.\\n    \"\"\"\\n\\n    search_engine: Any  #: :meta private:\\n    params: dict = Field(\\n        default={\\n            \"engine\": \"google\",\\n            \"google_domain\": \"google.com\",\\n            \"gl\": \"us\",\\n            \"hl\": \"en\",\\n        }\\n    )\\n    config = Config()\\n    serpapi_api_key: Optional[str] = config.serpapi_api_key\\n    aiosession: Optional[aiohttp.ClientSession] = None\\n\\n    class Config:\\n        arbitrary_types_allowed = True\\n\\n    async def run(self, query: str, **kwargs: Any) -> str:\\n        \"\"\"Run query through SerpAPI and parse result async.\"\"\"\\n        return self._process_response(await self.results(query))\\n\\n    async def results(self, query: str) -> dict:\\n        \"\"\"Use aiohttp to run query through SerpAPI and return the results async.\"\"\"\\n\\n        def construct_url_and_params() -> Tuple[str, Dict[str, str]]:\\n            params = self.get_params(query)\\n            params[\"source\"] = \"python\"\\n            if self.serpapi_api_key:\\n                params[\"serp_api_key\"] = self.serpapi_api_key\\n            params[\"output\"] = \"json\"\\n            url = \"https://serpapi.com/search\"\\n            return url, params\\n\\n        url, params = construct_url_and_params()\\n        if not self.aiosession:\\n            async with aiohttp.ClientSession() as session:\\n                async with session.get(url, params=params) as response:\\n                    res = await response.json()\\n        else:\\n            async with self.aiosession.get(url, params=params) as response:\\n                res = await response.json()\\n\\n        return res\\n\\n    def get_params(self, query: str) -> Dict[str, str]:\\n        \"\"\"Get parameters for SerpAPI.\"\"\"\\n        _params = {\\n            \"api_key\": self.serpapi_api_key,\\n            \"q\": query,\\n        }\\n        params = {**self.params, **_params}\\n        return params\\n\\n    @staticmethod\\n    def _process_response(res: dict) -> str:\\n        \"\"\"Process response from SerpAPI.\"\"\"\\n        # logger.debug(res)\\n        focus = [\\'title\\', \\'snippet\\', \\'link\\']\\n        get_focused = lambda x: {i: j for i, j in x.items() if i in focus}\\n\\n        if \"error\" in res.keys():\\n            raise ValueError(f\"Got error from SerpAPI: {res[\\'error\\']}\")\\n        if \"answer_box\" in res.keys() and \"answer\" in res[\"answer_box\"].keys():\\n            toret = res[\"answer_box\"][\"answer\"]\\n        elif \"answer_box\" in res.keys() and \"snippet\" in res[\"answer_box\"].keys():\\n            toret = res[\"answer_box\"][\"snippet\"]\\n        elif (\\n            \"answer_box\" in res.keys()\\n            and \"snippet_highlighted_words\" in res[\"answer_box\"].keys()\\n        ):\\n            toret = res[\"answer_box\"][\"snippet_highlighted_words\"][0]\\n        elif (\\n            \"sports_results\" in res.keys()\\n            and \"game_spotlight\" in res[\"sports_results\"].keys()\\n        ):\\n            toret = res[\"sports_results\"][\"game_spotlight\"]\\n        elif (\\n            \"knowledge_graph\" in res.keys()\\n            and \"description\" in res[\"knowledge_graph\"].keys()\\n        ):\\n            toret = res[\"knowledge_graph\"][\"description\"]\\n        elif \"snippet\" in res[\"organic_results\"][0].keys():\\n            toret = res[\"organic_results\"][0][\"snippet\"]\\n        else:\\n            toret = \"No good search result found\"\\n\\n        toret_l = []\\n        if \"answer_box\" in res.keys() and \"snippet\" in res[\"answer_box\"].keys():\\n            toret_l += [get_focused(res[\"answer_box\"])]\\n        if res.get(\"organic_results\"):\\n            toret_l += [get_focused(i) for i in res.get(\"organic_results\")]\\n\\n        return str(toret) + \\'\\\\n\\' + str(toret_l)'}),\n",
       " '1ba3ad47-8814-4e66-9353-d18d5e139614': Document(page_content='Python class for wrapping and interacting with Playwright, a tool for browser automation. It provides methods for launching a browser, navigating to URLs, and scraping page content. The class handles pre-checks and configurations for the browser type and executable path.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/web_browser_engine_playwright.py'), 'class_name': 'PlaywrightWrapper', 'summary': 'This source code is a Python class called `PlaywrightWrapper` that serves as a wrapper around the Playwright library. It provides a convenient way to automate web browsing and scraping tasks using different browser types such as Chromium, Firefox, or WebKit. The class includes methods for initializing the wrapper, running web browser instances, scraping web content, and performing pre-checks for browser installations.', 'code': 'class PlaywrightWrapper:\\n    \"\"\"Wrapper around Playwright.\\n\\n    To use this module, you should have the `playwright` Python package installed and ensure that\\n    the required browsers are also installed. You can install playwright by running the command\\n    `pip install metagpt[playwright]` and download the necessary browser binaries by running the\\n    command `playwright install` for the first time.\"\\n    \"\"\"\\n\\n    def __init__(\\n        self,\\n        browser_type: Literal[\"chromium\", \"firefox\", \"webkit\"] | None = None,\\n        launch_kwargs: dict | None = None,\\n        **kwargs,\\n    ) -> None:\\n        if browser_type is None:\\n            browser_type = CONFIG.playwright_browser_type\\n        self.browser_type = browser_type\\n        launch_kwargs = launch_kwargs or {}\\n        if CONFIG.global_proxy and \"proxy\" not in launch_kwargs:\\n            args = launch_kwargs.get(\"args\", [])\\n            if not any(str.startswith(i, \"--proxy-server=\") for i in args):\\n                launch_kwargs[\"proxy\"] = {\"server\": CONFIG.global_proxy}\\n        self.launch_kwargs = launch_kwargs\\n        context_kwargs = {}\\n        if \"ignore_https_errors\" in kwargs:\\n            context_kwargs[\"ignore_https_errors\"] = kwargs[\"ignore_https_errors\"]\\n        self._context_kwargs = context_kwargs\\n        self._has_run_precheck = False\\n\\n    async def run(self, url: str, *urls: str) -> str | list[str]:\\n        async with async_playwright() as ap:\\n            browser_type = getattr(ap, self.browser_type)\\n            await self._run_precheck(browser_type)\\n            browser = await browser_type.launch(**self.launch_kwargs)\\n\\n            async def _scrape(url):\\n                context = await browser.new_context(**self._context_kwargs)\\n                page = await context.new_page()\\n                async with page:\\n                    try:\\n                        await page.goto(url)\\n                        await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\\n                        content = await page.content()\\n                        return content\\n                    except Exception as e:\\n                        return f\"Fail to load page content for {e}\"\\n\\n            if urls:\\n                return await asyncio.gather(_scrape(url), *(_scrape(i) for i in urls))\\n            return await _scrape(url)\\n\\n    async def _run_precheck(self, browser_type):\\n        if self._has_run_precheck:\\n            return\\n\\n        executable_path = Path(browser_type.executable_path)\\n        if not executable_path.exists() and \"executable_path\" not in self.launch_kwargs:\\n            kwargs = {}\\n            if CONFIG.global_proxy:\\n                kwargs[\"env\"] = {\"ALL_PROXY\": CONFIG.global_proxy}\\n            await _install_browsers(self.browser_type, **kwargs)\\n            if not executable_path.exists():\\n                parts = executable_path.parts\\n                available_paths = list(Path(*parts[:-3]).glob(f\"{self.browser_type}-*\"))\\n                if available_paths:\\n                    logger.warning(\\n                        \"It seems that your OS is not officially supported by Playwright. \"\\n                        \"Try to set executable_path to the fallback build version.\"\\n                    )\\n                    executable_path = available_paths[0].joinpath(*parts[-2:])\\n                    self.launch_kwargs[\"executable_path\"] = str(executable_path)\\n        self._has_run_precheck = True\\n'}),\n",
       " 'a165ccf4-eab1-4e64-bbe3-a4ec0a2b2794': Document(page_content='Python class for a search engine with different search engine options and functionality.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/search_engine.py'), 'class_name': 'SearchEngine', 'summary': 'This source code defines a `SearchEngine` class that can be used to perform searches using different search engines. It has a variety of options for search engines, including Google, DuckDuckGo, and custom engines. The `run` method is used to execute the search and returns the search results.', 'code': 'class SearchEngine:\\n    \"\"\"\\n    TODO: 合入Google Search 并进行反代\\n    注：这里Google需要挂Proxifier或者类似全局代理\\n    - DDG: https://pypi.org/project/duckduckgo-search/\\n    - GOOGLE: https://programmablesearchengine.google.com/controlpanel/overview?cx=63f9de531d0e24de9\\n    \"\"\"\\n    def __init__(self, engine=None, run_func=None):\\n        self.config = Config()\\n        self.run_func = run_func\\n        self.engine = engine or self.config.search_engine\\n\\n    @classmethod\\n    def run_google(cls, query, max_results=8):\\n        # results = ddg(query, max_results=max_results)\\n        results = google_official_search(query, num_results=max_results)\\n        logger.info(results)\\n        return results\\n\\n    async def run(self, query: str, max_results=8):\\n        if self.engine == SearchEngineType.SERPAPI_GOOGLE:\\n            api = SerpAPIWrapper()\\n            rsp = await api.run(query)\\n        elif self.engine == SearchEngineType.DIRECT_GOOGLE:\\n            rsp = SearchEngine.run_google(query, max_results)\\n        elif self.engine == SearchEngineType.SERPER_GOOGLE:\\n            api = SerperWrapper()\\n            rsp = await api.run(query)\\n        elif self.engine == SearchEngineType.CUSTOM_ENGINE:\\n            rsp = self.run_func(query)\\n        else:\\n            raise NotImplementedError\\n        return rsp\\n'}),\n",
       " '711caaab-6726-4b8c-9e12-eb6354d416d1': Document(page_content='Web Browser Engine Class for running and parsing web pages', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/web_browser_engine.py'), 'class_name': 'WebBrowserEngine', 'summary': 'This source code defines a `WebBrowserEngine` class with an `__init__` method that initializes the engine, run function, and parse function for the web browser. The engine can be of different types (Playwright, Selenium, or Custom), and the appropriate modules are imported based on the engine type. The class also has a `run` method that makes use of the run function to retrieve web page content and parse it using the parse function.', 'code': 'class WebBrowserEngine:\\n    def __init__(\\n        self,\\n        engine: WebBrowserEngineType | None = None,\\n        run_func: Callable[..., Coroutine[Any, Any, str | list[str]]] | None = None,\\n        parse_func: Callable[[str], str] | None = None,\\n    ):\\n        engine = engine or CONFIG.web_browser_engine\\n\\n        if engine == WebBrowserEngineType.PLAYWRIGHT:\\n            module = \"metagpt.tools.web_browser_engine_playwright\"\\n            run_func = importlib.import_module(module).PlaywrightWrapper().run\\n        elif engine == WebBrowserEngineType.SELENIUM:\\n            module = \"metagpt.tools.web_browser_engine_selenium\"\\n            run_func = importlib.import_module(module).SeleniumWrapper().run\\n        elif engine == WebBrowserEngineType.CUSTOM:\\n            run_func = run_func\\n        else:\\n            raise NotImplementedError\\n        self.parse_func = parse_func or get_page_content\\n        self.run_func = run_func\\n        self.engine = engine\\n\\n    @overload\\n    async def run(self, url: str) -> str:\\n        ...\\n\\n    @overload\\n    async def run(self, url: str, *urls: str) -> list[str]:\\n        ...\\n\\n    async def run(self, url: str, *urls: str) -> str | list[str]:\\n        page = await self.run_func(url, *urls)\\n        if isinstance(page, str):\\n            return self.parse_func(page)\\n        return [self.parse_func(i) for i in page]\\n'}),\n",
       " '4e43f02a-3b04-4a7b-a156-0754662d4036': Document(page_content='SerpAPI Wrapper for Google Search Results', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/search_engine_serper.py'), 'class_name': 'SerperWrapper', 'summary': 'This source code defines a class `SerperWrapper` that acts as a wrapper around the SerpAPI. It provides methods to run queries on the SerpAPI asynchronously and parse the results. The class uses the `google-search-results` package and requires an API key to be set either in the environment variable `SERPAPI_API_KEY` or passed as a parameter to the constructor.', 'code': 'class SerperWrapper(BaseModel):\\n    \"\"\"Wrapper around SerpAPI.\\n\\n    To use, you should have the ``google-search-results`` python package installed,\\n    and the environment variable ``SERPAPI_API_KEY`` set with your API key, or pass\\n    `serpapi_api_key` as a named parameter to the constructor.\\n    \"\"\"\\n\\n    search_engine: Any  #: :meta private:\\n    payload: dict = Field(\\n        default={\\n            \"page\": 1,\\n            \"num\": 10\\n        }\\n    )\\n    config = Config()\\n    serper_api_key: Optional[str] = config.serper_api_key\\n    aiosession: Optional[aiohttp.ClientSession] = None\\n\\n    class Config:\\n        arbitrary_types_allowed = True\\n\\n    async def run(self, query: str, **kwargs: Any) -> str:\\n        \"\"\"Run query through Serper and parse result async.\"\"\"\\n        queries = query.split(\"\\\\n\")\\n        return \"\\\\n\".join([self._process_response(res) for res in await self.results(queries)])\\n\\n    async def results(self, queries: list[str]) -> dict:\\n        \"\"\"Use aiohttp to run query through Serper and return the results async.\"\"\"\\n\\n        def construct_url_and_payload_and_headers() -> Tuple[str, Dict[str, str]]:\\n            payloads = self.get_payloads(queries)\\n            url = \"https://google.serper.dev/search\"\\n            headers = self.get_headers()\\n            return url, payloads, headers\\n\\n        url, payloads, headers = construct_url_and_payload_and_headers()\\n        if not self.aiosession:\\n            async with aiohttp.ClientSession() as session:\\n                async with session.post(url, data=payloads, headers=headers) as response:\\n                    res = await response.json()\\n        else:\\n            async with self.aiosession.get.post(url, data=payloads, headers=headers) as response:\\n                res = await response.json()\\n\\n        return res\\n\\n    def get_payloads(self, queries: list[str]) -> Dict[str, str]:\\n        \"\"\"Get payloads for Serper.\"\"\"\\n        payloads = []\\n        for query in queries:\\n            _payload = {\\n                \"q\": query,\\n            }\\n            payloads.append({**self.payload, **_payload})\\n        return json.dumps(payloads, sort_keys=True)\\n\\n    def get_headers(self) -> Dict[str, str]:\\n        headers = {\\n            \\'X-API-KEY\\':  self.serper_api_key,\\n            \\'Content-Type\\': \\'application/json\\'\\n        }\\n        return headers\\n\\n    @staticmethod\\n    def _process_response(res: dict) -> str:\\n        \"\"\"Process response from SerpAPI.\"\"\"\\n        # logger.debug(res)\\n        focus = [\\'title\\', \\'snippet\\', \\'link\\']\\n        def get_focused(x): return {i: j for i, j in x.items() if i in focus}\\n\\n        if \"error\" in res.keys():\\n            raise ValueError(f\"Got error from SerpAPI: {res[\\'error\\']}\")\\n        if \"answer_box\" in res.keys() and \"answer\" in res[\"answer_box\"].keys():\\n            toret = res[\"answer_box\"][\"answer\"]\\n        elif \"answer_box\" in res.keys() and \"snippet\" in res[\"answer_box\"].keys():\\n            toret = res[\"answer_box\"][\"snippet\"]\\n        elif (\\n            \"answer_box\" in res.keys()\\n            and \"snippet_highlighted_words\" in res[\"answer_box\"].keys()\\n        ):\\n            toret = res[\"answer_box\"][\"snippet_highlighted_words\"][0]\\n        elif (\\n            \"sports_results\" in res.keys()\\n            and \"game_spotlight\" in res[\"sports_results\"].keys()\\n        ):\\n            toret = res[\"sports_results\"][\"game_spotlight\"]\\n        elif (\\n            \"knowledge_graph\" in res.keys()\\n            and \"description\" in res[\"knowledge_graph\"].keys()\\n        ):\\n            toret = res[\"knowledge_graph\"][\"description\"]\\n        elif \"snippet\" in res[\"organic\"][0].keys():\\n            toret = res[\"organic\"][0][\"snippet\"]\\n        else:\\n            toret = \"No good search result found\"\\n\\n        toret_l = []\\n        if \"answer_box\" in res.keys() and \"snippet\" in res[\"answer_box\"].keys():\\n            toret_l += [get_focused(res[\"answer_box\"])]\\n        if res.get(\"organic\"):\\n            toret_l += [get_focused(i) for i in res.get(\"organic\")]\\n\\n        return str(toret) + \\'\\\\n\\' + str(toret_l)'}),\n",
       " '9b705a39-5a02-46c3-ae14-3447551c3dae': Document(page_content='Python code defining a class with different search engine types as enumerated values.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/__init__.py'), 'class_name': 'SearchEngineType', 'summary': 'This code defines a class `SearchEngineType` with four members: `SERPAPI_GOOGLE`, `DIRECT_GOOGLE`, `SERPER_GOOGLE`, and `CUSTOM_ENGINE`.', 'code': 'class SearchEngineType(Enum):\\n    SERPAPI_GOOGLE = auto()\\n    DIRECT_GOOGLE = auto()\\n    SERPER_GOOGLE = auto()\\n    CUSTOM_ENGINE = auto()\\n'}),\n",
       " 'e26c4e1a-e7e5-405a-912a-2136f5353d39': Document(page_content='Enum for web browser engine types', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/__init__.py'), 'class_name': 'WebBrowserEngineType', 'summary': 'This code defines an enumeration class called `WebBrowserEngineType` with three members: `PLAYWRIGHT`, `SELENIUM`, and `CUSTOM`. These members are assigned the string values `\"playwright\"`, `\"selenium\"`, and `\"custom\"` respectively. This enum will be useful for identifying different types of web browser engines in a Python program.', 'code': 'class WebBrowserEngineType(Enum):\\n    PLAYWRIGHT = \"playwright\"\\n    SELENIUM = \"selenium\"\\n    CUSTOM = \"custom\"'}),\n",
       " '4b0d871b-3dfe-4426-b542-2188d87cac81': Document(page_content='Selenium Wrapper for Web Scraping', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/web_browser_engine_selenium.py'), 'class_name': 'SeleniumWrapper', 'summary': 'This source code defines a `SeleniumWrapper` class that serves as a wrapper around Selenium, a popular web scraping and automation tool. It provides a straightforward interface for scraping web pages using Selenium and includes instructions for setting up the necessary dependencies and WebDriver. The `run` method can be used to scrape a single URL or multiple URLs asynchronously, while the `_run_precheck` method initializes the required setup before scraping.', 'code': 'class SeleniumWrapper:\\n    \"\"\"Wrapper around Selenium.\\n\\n    To use this module, you should check the following:\\n\\n    1. Run the following command: pip install metagpt[selenium].\\n    2. Make sure you have a compatible web browser installed and the appropriate WebDriver set up\\n       for that browser before running. For example, if you have Mozilla Firefox installed on your\\n       computer, you can set the configuration SELENIUM_BROWSER_TYPE to firefox. After that, you\\n       can scrape web pages using the Selenium WebBrowserEngine.\\n    \"\"\"\\n\\n    def __init__(\\n        self,\\n        browser_type: Literal[\"chrome\", \"firefox\", \"edge\", \"ie\"] | None = None,\\n        launch_kwargs: dict | None = None,\\n        *,\\n        loop: asyncio.AbstractEventLoop | None = None,\\n        executor: futures.Executor | None = None,\\n    ) -> None:\\n        if browser_type is None:\\n            browser_type = CONFIG.selenium_browser_type\\n        self.browser_type = browser_type\\n        launch_kwargs = launch_kwargs or {}\\n        if CONFIG.global_proxy and \"proxy-server\" not in launch_kwargs:\\n            launch_kwargs[\"proxy-server\"] = CONFIG.global_proxy\\n\\n        self.executable_path = launch_kwargs.pop(\"executable_path\", None)\\n        self.launch_args = [f\"--{k}={v}\" for k, v in launch_kwargs.items()]\\n        self._has_run_precheck = False\\n        self._get_driver = None\\n        self.loop = loop\\n        self.executor = executor\\n\\n    async def run(self, url: str, *urls: str) -> str | list[str]:\\n        await self._run_precheck()\\n\\n        _scrape = lambda url: self.loop.run_in_executor(self.executor, self._scrape_website, url)\\n\\n        if urls:\\n            return await asyncio.gather(_scrape(url), *(_scrape(i) for i in urls))\\n        return await _scrape(url)\\n\\n    async def _run_precheck(self):\\n        if self._has_run_precheck:\\n            return\\n        self.loop = self.loop or asyncio.get_event_loop()\\n        self._get_driver = await self.loop.run_in_executor(\\n            self.executor,\\n            lambda: _gen_get_driver_func(self.browser_type, *self.launch_args, executable_path=self.executable_path),\\n        )\\n        self._has_run_precheck = True\\n\\n    def _scrape_website(self, url):\\n        with self._get_driver() as driver:\\n            driver.get(url)\\n            WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\\n            return driver.page_source\\n'}),\n",
       " 'ec14e616-a93d-4859-b84c-bb10cb1ed006': Document(page_content='Class for running an SD (Semantic Diffusion) engine, which performs image-to-image and text-to-image tasks using the SD API. It initializes with configuration settings, constructs payloads for the API, saves images, and asynchronously runs the API for multiple prompts. It also has methods for running image-to-image and SAM (Style Augmentation Module) tasks, but they are not implemented yet.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/sd_engine.py'), 'class_name': 'SDEngine', 'summary': 'This source code defines a class called `SDEngine`, which is used to interact with an SD API. The class has methods to initialize the engine, construct the payload for the API, save images, and run the API for multiple prompts asynchronously. Additionally, there are placeholders for future methods related to image-to-image generation and SAM.', 'code': 'class SDEngine:\\n    def __init__(self):\\n        # Initialize the SDEngine with configuration\\n        self.config = Config()\\n        self.sd_url = self.config.get(\\'SD_URL\\')\\n        self.sd_t2i_url = f\"{self.sd_url}{self.config.get(\\'SD_T2I_API\\')}\"\\n        # Define default payload settings for SD API\\n        self.payload = payload\\n        logger.info(self.sd_t2i_url)\\n    \\n    def construct_payload(self, prompt, negtive_prompt=default_negative_prompt, width=512, height=512,\\n                          sd_model=\"galaxytimemachinesGTM_photoV20\"):\\n        # Configure the payload with provided inputs\\n        self.payload[\"prompt\"] = prompt\\n        self.payload[\"negtive_prompt\"] = negtive_prompt\\n        self.payload[\"width\"] = width\\n        self.payload[\"height\"] = height\\n        self.payload[\"override_settings\"][\"sd_model_checkpoint\"] = sd_model\\n        logger.info(f\"call sd payload is {self.payload}\")\\n        return self.payload\\n    \\n    def _save(self, imgs, save_name=\"\"):\\n        save_dir = WORKSPACE_ROOT / \"resources\"/\"SD_Output\"\\n        if not os.path.exists(save_dir):\\n            os.makedirs(save_dir, exist_ok=True)\\n        batch_decode_base64_to_image(imgs, save_dir, save_name=save_name)\\n     \\n    async def run_t2i(self, prompts: List):\\n        # Asynchronously run the SD API for multiple prompts\\n        session = ClientSession()\\n        for payload_idx, payload in enumerate(prompts):\\n            results = await self.run(url=self.sd_t2i_url, payload=payload, session=session)\\n            self._save(results, save_name=f\"output_{payload_idx}\")\\n        await session.close()\\n    \\n    async def run(self, url, payload, session):\\n        # Perform the HTTP POST request to the SD API\\n        async with session.post(url, json=payload, timeout=600) as rsp:\\n            data = await rsp.read()\\n        \\n        rsp_json = json.loads(data)\\n        imgs = rsp_json[\\'images\\']\\n        logger.info(f\"callback rsp json is {rsp_json.keys()}\")\\n        return imgs\\n    \\n    async def run_i2i(self):\\n        # todo: 添加图生图接口调用\\n        raise NotImplementedError\\n    \\n    async def run_sam(self):\\n        # todo：添加SAM接口调用\\n        raise NotImplementedError\\n'}),\n",
       " '36e187aa-7b49-4dc1-9c5b-f4245ebd4bd1': Document(page_content='UTGenerator class: A class for generating unit tests based on an API documentation (Swagger JSON).', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/ut_writer.py'), 'class_name': 'UTGenerator', 'summary': 'This source code defines a class called `UTGenerator` which is used to generate unit test cases based on an API documentation. The class has methods to initialize the generator, load the Swagger JSON, convert parameters into a string representation, build the properties of an object or array, map tags to paths in the API documentation, generate test cases, and save the generated questions and answers. Additionally, it has methods to build the API documentation, send messages to a GPT model for code generation, and get the file path for saving files.', 'code': 'class UTGenerator:\\n    \"\"\"UT生成器：通过API文档构造UT\"\"\"\\n\\n    def __init__(self, swagger_file: str, ut_py_path: str, questions_path: str,\\n                 chatgpt_method: str = \"API\", template_prefix=YFT_PROMPT_PREFIX) -> None:\\n        \"\"\"初始化UT生成器\\n\\n        Args:\\n            swagger_file: swagger路径\\n            ut_py_path: 用例存放路径\\n            questions_path: 模版存放路径，便于后续排查\\n            chatgpt_method: API\\n            template_prefix: 使用模版，默认使用YFT_UT_PROMPT\\n        \"\"\"\\n        self.swagger_file = swagger_file\\n        self.ut_py_path = ut_py_path\\n        self.questions_path = questions_path\\n        assert chatgpt_method in [\"API\"], \"非法chatgpt_method\"\\n        self.chatgpt_method = chatgpt_method\\n\\n        # ICL: In-Context Learning，这里给出例子，要求GPT模仿例子\\n        self.icl_sample = ICL_SAMPLE\\n        self.template_prefix = template_prefix\\n\\n    def get_swagger_json(self) -> dict:\\n        \"\"\"从本地文件加载Swagger JSON\"\"\"\\n        with open(self.swagger_file, \"r\", encoding=\"utf-8\") as file:\\n            swagger_json = json.load(file)\\n        return swagger_json\\n\\n    def __para_to_str(self, prop, required, name=\"\"):\\n        name = name or prop[\"name\"]\\n        ptype = prop[\"type\"]\\n        title = prop.get(\"title\", \"\")\\n        desc = prop.get(\"description\", \"\")\\n        return f\\'{name}\\\\t{ptype}\\\\t{\"是\" if required else \"否\"}\\\\t{title}\\\\t{desc}\\'\\n\\n    def _para_to_str(self, prop):\\n        required = prop.get(\"required\", False)\\n        return self.__para_to_str(prop, required)\\n\\n    def para_to_str(self, name, prop, prop_object_required):\\n        required = name in prop_object_required\\n        return self.__para_to_str(prop, required, name)\\n\\n    def build_object_properties(self, node, prop_object_required, level: int = 0) -> str:\\n        \"\"\"递归输出object和array[object]类型的子属性\\n\\n        Args:\\n            node (_type_): 子项的值\\n            prop_object_required (_type_): 是否必填项\\n            level: 当前递归深度\\n        \"\"\"\\n\\n        doc = \"\"\\n\\n        def dive_into_object(node):\\n            \"\"\"如果是object类型，递归输出子属性\"\"\"\\n            if node.get(\"type\") == \"object\":\\n                sub_properties = node.get(\"properties\", {})\\n                return self.build_object_properties(sub_properties, prop_object_required, level=level + 1)\\n            return \"\"\\n\\n        if node.get(\"in\", \"\") in [\"query\", \"header\", \"formData\"]:\\n            doc += f\\'{\"\\t\" * level}{self._para_to_str(node)}\\\\n\\'\\n            doc += dive_into_object(node)\\n            return doc\\n\\n        for name, prop in node.items():\\n            doc += f\\'{\"\\t\" * level}{self.para_to_str(name, prop, prop_object_required)}\\\\n\\'\\n            doc += dive_into_object(prop)\\n            if prop[\"type\"] == \"array\":\\n                items = prop.get(\"items\", {})\\n                doc += dive_into_object(items)\\n        return doc\\n\\n    def get_tags_mapping(self) -> dict:\\n        \"\"\"处理tag与path\\n\\n        Returns:\\n            Dict: tag: path对应关系\\n        \"\"\"\\n        swagger_data = self.get_swagger_json()\\n        paths = swagger_data[\"paths\"]\\n        tags = {}\\n\\n        for path, path_obj in paths.items():\\n            for method, method_obj in path_obj.items():\\n                for tag in method_obj[\"tags\"]:\\n                    if tag not in tags:\\n                        tags[tag] = {}\\n                    if path not in tags[tag]:\\n                        tags[tag][path] = {}\\n                    tags[tag][path][method] = method_obj\\n\\n        return tags\\n\\n    def generate_ut(self, include_tags) -> bool:\\n        \"\"\"生成用例文件\"\"\"\\n        tags = self.get_tags_mapping()\\n        for tag, paths in tags.items():\\n            if include_tags is None or tag in include_tags:\\n                self._generate_ut(tag, paths)\\n        return True\\n\\n    def build_api_doc(self, node: dict, path: str, method: str) -> str:\\n        summary = node[\"summary\"]\\n\\n        doc = f\"接口名称：{summary}\\\\n接口路径：{path}\\\\nMethod：{method.upper()}\\\\n\"\\n        doc += \"\\\\n请求参数：\\\\n\"\\n        if \"parameters\" in node:\\n            parameters = node[\"parameters\"]\\n            doc += \"路径参数：\\\\n\"\\n\\n            # param[\"in\"]: path / formData / body / query / header\\n            for param in parameters:\\n                if param[\"in\"] == \"path\":\\n                    doc += f\\'{param[\"name\"]} \\\\n\\'\\n\\n            doc += \"\\\\nBody参数：\\\\n\"\\n            doc += \"名称\\\\t类型\\\\t是否必须\\\\t默认值\\\\t备注\\\\n\"\\n            for param in parameters:\\n                if param[\"in\"] == \"body\":\\n                    schema = param.get(\"schema\", {})\\n                    prop_properties = schema.get(\"properties\", {})\\n                    prop_required = schema.get(\"required\", [])\\n                    doc += self.build_object_properties(prop_properties, prop_required)\\n                else:\\n                    doc += self.build_object_properties(param, [])\\n\\n        # 输出返回数据信息\\n        doc += \"\\\\n返回数据：\\\\n\"\\n        doc += \"名称\\\\t类型\\\\t是否必须\\\\t默认值\\\\t备注\\\\n\"\\n        responses = node[\"responses\"]\\n        response = responses.get(\"200\", {})\\n        schema = response.get(\"schema\", {})\\n        properties = schema.get(\"properties\", {})\\n        required = schema.get(\"required\", {})\\n\\n        doc += self.build_object_properties(properties, required)\\n        doc += \"\\\\n\"\\n        doc += \"```\"\\n\\n        return doc\\n\\n    def _store(self, data, base, folder, fname):\\n        file_path = self.get_file_path(Path(base) / folder, fname)\\n        with open(file_path, \"w\", encoding=\"utf-8\") as file:\\n            file.write(data)\\n\\n    def ask_gpt_and_save(self, question: str, tag: str, fname: str):\\n        \"\"\"生成问题，并且存储问题与答案\"\"\"\\n        messages = [self.icl_sample, question]\\n        result = self.gpt_msgs_to_code(messages=messages)\\n\\n        self._store(question, self.questions_path, tag, f\"{fname}.txt\")\\n        self._store(result, self.ut_py_path, tag, f\"{fname}.py\")\\n\\n    def _generate_ut(self, tag, paths):\\n        \"\"\"处理数据路径下的结构\\n\\n        Args:\\n            tag (_type_): 模块名称\\n            paths (_type_): 路径Object\\n        \"\"\"\\n        for path, path_obj in paths.items():\\n            for method, node in path_obj.items():\\n                summary = node[\"summary\"]\\n                question = self.template_prefix\\n                question += self.build_api_doc(node, path, method)\\n                self.ask_gpt_and_save(question, tag, summary)\\n\\n    def gpt_msgs_to_code(self, messages: list) -> str:\\n        \"\"\"根据不同调用方式选择\"\"\"\\n        result = \\'\\'\\n        if self.chatgpt_method == \"API\":\\n            result = GPTAPI().ask_code(msgs=messages)\\n\\n        return result\\n\\n    def get_file_path(self, base: Path, fname: str):\\n        \"\"\"保存不同的文件路径\\n\\n        Args:\\n            base (str): 路径\\n            fname (str): 文件名称\\n        \"\"\"\\n        path = Path(base)\\n        path.mkdir(parents=True, exist_ok=True)\\n        file_path = path / fname\\n        return str(file_path)'}),\n",
       " 'a802420a-c90b-4eb9-a314-0472372df9aa': Document(page_content='Python class method for translating a prompt to a specific language', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/translator.py'), 'class_name': 'Translator', 'summary': 'The code defines a class called Translator with a method translate_prompt which takes an original text and an optional language argument and returns a translated prompt containing the original text and the specified language.', 'code': \"class Translator:\\n\\n    @classmethod\\n    def translate_prompt(cls, original, lang='中文'):\\n        return prompt.format(LANG=lang, ORIGINAL=original)\"}),\n",
       " '393b10cb-0691-4ffa-8d4b-beb28112cc4a': Document(page_content='Code tag: GPTPromptGenerator', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/prompt_writer.py'), 'class_name': 'GPTPromptGenerator', 'summary': 'This source code defines a class called `GPTPromptGenerator` that generates prompts for a language model like GPT. The class has methods for generating prompts in three different styles: instructions, chatbot conversations, and search queries. The `gen` method takes an example output and a style as input and returns the corresponding prompt(s) for the language model to generate the input.', 'code': 'class GPTPromptGenerator:\\n    \"\"\"通过LLM，给定输出，要求LLM给出输入（支持指令、对话、搜索三种风格）\"\"\"\\n    def __init__(self):\\n        self._generators = {i: getattr(self, f\"gen_{i}_style\") for i in [\\'instruction\\', \\'chatbot\\', \\'query\\']}\\n\\n    def gen_instruction_style(self, example):\\n        \"\"\"指令风格：给定输出，要求LLM给出输入\"\"\"\\n        return f\"\"\"指令：X\\n输出：{example}\\n这个输出可能来源于什么样的指令？\\nX：\"\"\"\\n\\n    def gen_chatbot_style(self, example):\\n        \"\"\"对话风格：给定输出，要求LLM给出输入\"\"\"\\n        return f\"\"\"你是一个对话机器人。一个用户给你发送了一条非正式的信息，你的回复如下。\\n信息：X\\n回复：{example}\\n非正式信息X是什么？\\nX：\"\"\"\\n\\n    def gen_query_style(self, example):\\n        \"\"\"搜索风格：给定输出，要求LLM给出输入\"\"\"\\n        return f\"\"\"你是一个搜索引擎。一个人详细地查询了某个问题，关于这个查询最相关的文档如下。\\n查询：X\\n文档：{example} 详细的查询X是什么？\\nX：\"\"\"\\n\\n    def gen(self, example: str, style: str = \\'all\\') -> Union[list[str], str]:\\n        \"\"\"\\n        通过example生成一个或多个输出，用于让LLM回复对应输入\\n\\n        :param example: LLM的预期输出样本\\n        :param style: (all|instruction|chatbot|query)\\n        :return: LLM的预期输入样本（一个或多个）\\n        \"\"\"\\n        if style != \\'all\\':\\n            return self._generators[style](example)\\n        return [f(example) for f in self._generators.values()]\\n'}),\n",
       " '70588550-3fcc-4b5e-9221-b144070bfb0e': Document(page_content='Code tag: \"Generating WikiHow prompts based on a question and step count\"', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/prompt_writer.py'), 'class_name': 'WikiHowTemplate', 'summary': 'The given code defines a class called `WikiHowTemplate` that has an initializer method and a generator method. The initializer method sets a string of prompts as an attribute. The generator method receives a question and a step as arguments and returns a list of prompts with the question and step substituted in the placeholders.', 'code': 'class WikiHowTemplate:\\n    def __init__(self):\\n        self._prompts = \"\"\"Give me {step} steps to {question}.\\nHow to {question}?\\nDo you know how can I {question}?\\nList {step} instructions to {question}.\\nWhat are some tips to {question}?\\nWhat are some steps to {question}?\\nCan you provide {step} clear and concise instructions on how to {question}?\\nI\\'m interested in learning how to {question}. Could you break it down into {step} easy-to-follow steps?\\nFor someone who is new to {question}, what would be {step} key steps to get started?\\nWhat is the most efficient way to {question}? Could you provide a list of {step} steps?\\nDo you have any advice on how to {question} successfully? Maybe a step-by-step guide with {step} steps?\\nI\\'m trying to accomplish {question}. Could you walk me through the process with {step} detailed instructions?\\nWhat are the essential {step} steps to {question}?\\nI need to {question}, but I\\'m not sure where to start. Can you give me {step} actionable steps?\\nAs a beginner in {question}, what are the {step} basic steps I should take?\\nI\\'m looking for a comprehensive guide on how to {question}. Can you provide {step} detailed steps?\\nCould you outline {step} practical steps to achieve {question}?\\nWhat are the {step} fundamental steps to consider when attempting to {question}?\"\"\"\\n\\n    def gen(self, question: str, step: str) -> list[str]:\\n        return self._prompts.format(question=question, step=step).splitlines()\\n'}),\n",
       " '40dca288-0528-4769-ae50-90b53bc2e9b8': Document(page_content='Email generation template.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/prompt_writer.py'), 'class_name': 'EnronTemplate', 'summary': 'The given source code defines a class called `EnronTemplate` with a method `gen`. The `gen` method takes a string `subj` as input and returns a list of email prompts with the `subj` variable substituted into each prompt. The email prompts are stored in the `_prompts` attribute of the class.', 'code': 'class EnronTemplate:\\n    def __init__(self):\\n        self._prompts = \"\"\"Write an email with the subject \"{subj}\".\\nCan you craft an email with the subject {subj}?\\nWould you be able to compose an email and use {subj} as the subject?\\nCreate an email about {subj}.\\nDraft an email and include the subject \"{subj}\".\\nGenerate an email about {subj}.\\nHey, can you shoot me an email about {subj}?\\nDo you mind crafting an email for me with {subj} as the subject?\\nCan you whip up an email with the subject of \"{subj}\"?\\nHey, can you write an email and use \"{subj}\" as the subject?\\nCan you send me an email about {subj}?\"\"\"\\n\\n    def gen(self, subj):\\n        return self._prompts.format(subj=subj).splitlines()\\n'}),\n",
       " '4689a6d8-3919-49a0-9a76-7b0c6ce5f991': Document(page_content='Python class to generate a list of prompts for editing and revising documents.', metadata={'file_path': PosixPath('MetaGPT/metagpt/tools/prompt_writer.py'), 'class_name': 'BEAGECTemplate', 'summary': 'This source code defines a Python class called \"BEAGECTemplate\" that has an attribute \"self._prompts\" which contains a large string of prompts for editing and revising a document. The class also has a method \"gen()\" that splits the prompts string into a list of individual prompts and returns it.', 'code': 'class BEAGECTemplate:\\n    def __init__(self):\\n        self._prompts = \"\"\"Edit and revise this document to improve its grammar, vocabulary, spelling, and style.\\nRevise this document to correct all the errors related to grammar, spelling, and style.\\nRefine this document by eliminating all grammatical, lexical, and orthographic errors and improving its writing style.\\nPolish this document by rectifying all errors related to grammar, vocabulary, and writing style.\\nEnhance this document by correcting all the grammar errors and style issues, and improving its overall quality.\\nRewrite this document by fixing all grammatical, lexical and orthographic errors.\\nFix all grammar errors and style issues and rewrite this document.\\nTake a stab at fixing all the mistakes in this document and make it sound better.\\nGive this document a once-over and clean up any grammar or spelling errors.\\nTweak this document to make it read smoother and fix any mistakes you see.\\nMake this document sound better by fixing all the grammar, spelling, and style issues.\\nProofread this document and fix any errors that make it sound weird or confusing.\"\"\"\\n\\n    def gen(self):\\n        return self._prompts.splitlines()'}),\n",
       " '3025ba48-6e91-4b9b-810d-99e218638626': Document(page_content='Memory class for managing and retrieving messages stored in memory.', metadata={'file_path': PosixPath('MetaGPT/metagpt/memory/memory.py'), 'class_name': 'Memory', 'summary': 'This source code defines a class called `Memory` which represents a basic memory storage system. It has methods to add, delete, and retrieve messages from storage, as well as methods to perform searches and counting operations. The class also maintains an index to efficiently retrieve messages based on different criteria, such as role, content, cause, and action.', 'code': 'class Memory:\\n    \"\"\"The most basic memory: super-memory\"\"\"\\n\\n    def __init__(self):\\n        \"\"\"Initialize an empty storage list and an empty index dictionary\"\"\"\\n        self.storage: list[Message] = []\\n        self.index: dict[Type[Action], list[Message]] = defaultdict(list)\\n\\n    def add(self, message: Message):\\n        \"\"\"Add a new message to storage, while updating the index\"\"\"\\n        if message in self.storage:\\n            return\\n        self.storage.append(message)\\n        if message.cause_by:\\n            self.index[message.cause_by].append(message)\\n\\n    def add_batch(self, messages: Iterable[Message]):\\n        for message in messages:\\n            self.add(message)\\n\\n    def get_by_role(self, role: str) -> list[Message]:\\n        \"\"\"Return all messages of a specified role\"\"\"\\n        return [message for message in self.storage if message.role == role]\\n\\n    def get_by_content(self, content: str) -> list[Message]:\\n        \"\"\"Return all messages containing a specified content\"\"\"\\n        return [message for message in self.storage if content in message.content]\\n\\n    def delete(self, message: Message):\\n        \"\"\"Delete the specified message from storage, while updating the index\"\"\"\\n        self.storage.remove(message)\\n        if message.cause_by and message in self.index[message.cause_by]:\\n            self.index[message.cause_by].remove(message)\\n\\n    def clear(self):\\n        \"\"\"Clear storage and index\"\"\"\\n        self.storage = []\\n        self.index = defaultdict(list)\\n\\n    def count(self) -> int:\\n        \"\"\"Return the number of messages in storage\"\"\"\\n        return len(self.storage)\\n\\n    def try_remember(self, keyword: str) -> list[Message]:\\n        \"\"\"Try to recall all messages containing a specified keyword\"\"\"\\n        return [message for message in self.storage if keyword in message.content]\\n\\n    def get(self, k=0) -> list[Message]:\\n        \"\"\"Return the most recent k memories, return all when k=0\"\"\"\\n        return self.storage[-k:]\\n\\n    def remember(self, observed: list[Message], k=10) -> list[Message]:\\n        \"\"\"remember the most recent k memories from observed Messages, return all when k=0\"\"\"\\n        already_observed = self.get(k)\\n        news: list[Message] = []\\n        for i in observed:\\n            if i in already_observed:\\n                continue\\n            news.append(i)\\n        return news\\n\\n    def get_by_action(self, action: Type[Action]) -> list[Message]:\\n        \"\"\"Return all messages triggered by a specified Action\"\"\"\\n        return self.index[action]\\n\\n    def get_by_actions(self, actions: Iterable[Type[Action]]) -> list[Message]:\\n        \"\"\"Return all messages triggered by specified Actions\"\"\"\\n        rsp = []\\n        for action in actions:\\n            if action not in self.index:\\n                continue\\n            rsp += self.index[action]\\n        return rsp'}),\n",
       " '11627303-b8b7-417c-bb1a-5660a4f9b8b0': Document(page_content='MemoryStorage class with Faiss as ANN search engine.', metadata={'file_path': PosixPath('MetaGPT/metagpt/memory/memory_storage.py'), 'class_name': 'MemoryStorage', 'summary': 'This source code defines a `MemoryStorage` class, which is a memory storage with Faiss as the ANN (Approximate Nearest Neighbor) search engine. The class has methods like `recover_memory`, `add`, `search`, and `clean` to perform various operations on the memory storage. It uses Faiss to store and retrieve messages, and provides functionality to filter similar messages based on a threshold.', 'code': 'class MemoryStorage(FaissStore):\\n    \"\"\"\\n    The memory storage with Faiss as ANN search engine\\n    \"\"\"\\n\\n    def __init__(self, mem_ttl: int = MEM_TTL):\\n        self.role_id: str = None\\n        self.role_mem_path: str = None\\n        self.mem_ttl: int = mem_ttl  # later use\\n        self.threshold: float = 0.1  # experience value. TODO The threshold to filter similar memories\\n        self._initialized: bool = False\\n\\n        self.store: FAISS = None  # Faiss engine\\n\\n    @property\\n    def is_initialized(self) -> bool:\\n        return self._initialized\\n\\n    def recover_memory(self, role_id: str) -> List[Message]:\\n        self.role_id = role_id\\n        self.role_mem_path = Path(DATA_PATH / f\\'role_mem/{self.role_id}/\\')\\n        self.role_mem_path.mkdir(parents=True, exist_ok=True)\\n\\n        self.store = self._load()\\n        messages = []\\n        if not self.store:\\n            # TODO init `self.store` under here with raw faiss api instead under `add`\\n            pass\\n        else:\\n            for _id, document in self.store.docstore._dict.items():\\n                messages.append(deserialize_message(document.metadata.get(\"message_ser\")))\\n            self._initialized = True\\n\\n        return messages\\n\\n    def _get_index_and_store_fname(self):\\n        if not self.role_mem_path:\\n            logger.error(f\\'You should call {self.__class__.__name__}.recover_memory fist when using LongTermMemory\\')\\n            return None, None\\n        index_fpath = Path(self.role_mem_path / f\\'{self.role_id}.index\\')\\n        storage_fpath = Path(self.role_mem_path / f\\'{self.role_id}.pkl\\')\\n        return index_fpath, storage_fpath\\n\\n    def persist(self):\\n        super(MemoryStorage, self).persist()\\n        logger.debug(f\\'Agent {self.role_id} persist memory into local\\')\\n\\n    def add(self, message: Message) -> bool:\\n        \"\"\" add message into memory storage\"\"\"\\n        docs = [message.content]\\n        metadatas = [{\"message_ser\": serialize_message(message)}]\\n        if not self.store:\\n            # init Faiss\\n            self.store = self._write(docs, metadatas)\\n            self._initialized = True\\n        else:\\n            self.store.add_texts(texts=docs, metadatas=metadatas)\\n        self.persist()\\n        logger.info(f\"Agent {self.role_id}\\'s memory_storage add a message\")\\n\\n    def search(self, message: Message, k=4) -> List[Message]:\\n        \"\"\"search for dissimilar messages\"\"\"\\n        if not self.store:\\n            return []\\n\\n        resp = self.store.similarity_search_with_score(\\n            query=message.content,\\n            k=k\\n        )\\n        # filter the result which score is smaller than the threshold\\n        filtered_resp = []\\n        for item, score in resp:\\n            # the smaller score means more similar relation\\n            if score < self.threshold:\\n                continue\\n            # convert search result into Memory\\n            metadata = item.metadata\\n            new_mem = deserialize_message(metadata.get(\"message_ser\"))\\n            filtered_resp.append(new_mem)\\n        return filtered_resp\\n\\n    def clean(self):\\n        index_fpath, storage_fpath = self._get_index_and_store_fname()\\n        if index_fpath and index_fpath.exists():\\n            index_fpath.unlink(missing_ok=True)\\n        if storage_fpath and storage_fpath.exists():\\n            storage_fpath.unlink(missing_ok=True)\\n\\n        self.store = None\\n        self._initialized = False'}),\n",
       " 'e997c1a5-4467-48e4-a83c-cdd477dae5b8': Document(page_content='Long-term memory for Roles', metadata={'file_path': PosixPath('MetaGPT/metagpt/memory/longterm_memory.py'), 'class_name': 'LongTermMemory', 'summary': 'This source code defines a class called `LongTermMemory` which is a type of `Memory`. It has methods to recover memory, add and delete messages, remember observed messages, and clear the memory. It also has an attribute `memory_storage` to store the memory and `rc` to store the RoleContext.', 'code': 'class LongTermMemory(Memory):\\n    \"\"\"\\n    The Long-term memory for Roles\\n    - recover memory when it staruped\\n    - update memory when it changed\\n    \"\"\"\\n\\n    def __init__(self):\\n        self.memory_storage: MemoryStorage = MemoryStorage()\\n        super(LongTermMemory, self).__init__()\\n        self.rc = None  # RoleContext\\n        self.msg_from_recover = False\\n\\n    def recover_memory(self, role_id: str, rc: \"RoleContext\"):\\n        messages = self.memory_storage.recover_memory(role_id)\\n        self.rc = rc\\n        if not self.memory_storage.is_initialized:\\n            logger.warning(f\\'It may the first time to run Agent {role_id}, the long-term memory is empty\\')\\n        else:\\n            logger.warning(f\\'Agent {role_id} has existed memory storage with {len(messages)} messages \\'\\n                           f\\'and has recovered them.\\')\\n        self.msg_from_recover = True\\n        self.add_batch(messages)\\n        self.msg_from_recover = False\\n\\n    def add(self, message: Message):\\n        super(LongTermMemory, self).add(message)\\n        for action in self.rc.watch:\\n            if message.cause_by == action and not self.msg_from_recover:\\n                # currently, only add role\\'s watching messages to its memory_storage\\n                # and ignore adding messages from recover repeatedly\\n                self.memory_storage.add(message)\\n\\n    def remember(self, observed: list[Message], k=10) -> list[Message]:\\n        \"\"\"\\n        remember the most similar k memories from observed Messages, return all when k=0\\n            1. remember the short-term memory(stm) news\\n            2. integrate the stm news with ltm(long-term memory) news\\n        \"\"\"\\n        stm_news = super(LongTermMemory, self).remember(observed)  # shot-term memory news\\n        if not self.memory_storage.is_initialized:\\n            # memory_storage hasn\\'t initialized, use default `remember` to get stm_news\\n            return stm_news\\n\\n        ltm_news: list[Message] = []\\n        for mem in stm_news:\\n            # integrate stm & ltm\\n            mem_searched = self.memory_storage.search(mem)\\n            if len(mem_searched) > 0:\\n                ltm_news.append(mem)\\n        return ltm_news[-k:]\\n\\n    def delete(self, message: Message):\\n        super(LongTermMemory, self).delete(message)\\n        # TODO delete message in memory_storage\\n\\n    def clear(self):\\n        super(LongTermMemory, self).clear()\\n        self.memory_storage.clean()'}),\n",
       " '2d2aa1f8-08a1-4182-92cb-ea7abb603151': Document(page_content='ChromaStore class for managing a collection in ChromaDB', metadata={'file_path': PosixPath('MetaGPT/metagpt/document_store/chromadb_store.py'), 'class_name': 'ChromaStore', 'summary': 'This source code defines a class called `ChromaStore` which is used for storing and querying data. It has methods for searching, writing, adding, and deleting documents in a collection. However, the `persist` method is not implemented. The class interacts with a database using the `chromadb` library.', 'code': 'class ChromaStore:\\n    \"\"\"如果从BaseStore继承，或者引入metagpt的其他模块，就会Python异常，很奇怪\"\"\"\\n    def __init__(self, name):\\n        client = chromadb.Client()\\n        collection = client.create_collection(name)\\n        self.client = client\\n        self.collection = collection\\n\\n    def search(self, query, n_results=2, metadata_filter=None, document_filter=None):\\n        # kwargs can be used for optional filtering\\n        results = self.collection.query(\\n            query_texts=[query],\\n            n_results=n_results,\\n            where=metadata_filter,  # optional filter\\n            where_document=document_filter  # optional filter\\n        )\\n        return results\\n\\n    def persist(self):\\n        \"\"\"chroma建议使用server模式，不本地persist\"\"\"\\n        raise NotImplementedError\\n\\n    def write(self, documents, metadatas, ids):\\n        # This function is similar to add(), but it\\'s for more generalized updates\\n        # It assumes you\\'re passing in lists of docs, metadatas, and ids\\n        return self.collection.add(\\n            documents=documents,\\n            metadatas=metadatas,\\n            ids=ids,\\n        )\\n\\n    def add(self, document, metadata, _id):\\n        # This function is for adding individual documents\\n        # It assumes you\\'re passing in a single doc, metadata, and id\\n        return self.collection.add(\\n            documents=[document],\\n            metadatas=[metadata],\\n            ids=[_id],\\n        )\\n\\n    def delete(self, _id):\\n        return self.collection.delete([_id])'}),\n",
       " '4d60edaf-3bc1-47e0-bb86-d56d32727c24': Document(page_content='Python code defining a class for a Milvus connection, with attributes for alias, host, and port.', metadata={'file_path': PosixPath('MetaGPT/metagpt/document_store/milvus_store.py'), 'class_name': 'MilvusConnection', 'summary': 'The code defines a typed dictionary called `MilvusConnection`.\\nIt has three keys: `alias`, `host`, and `port`, all of which have string values.\\nThis dictionary is used for creating connections to Milvus servers.', 'code': 'class MilvusConnection(TypedDict):\\n    alias: str\\n    host: str\\n    port: str\\n'}),\n",
       " 'e319b6b9-4a80-4203-ba33-c35cfc78e511': Document(page_content='MilvusStore class with methods for creating, dropping, loading, building index, searching, writing, and adding data to a collection in Milvus database.', metadata={'file_path': PosixPath('MetaGPT/metagpt/document_store/milvus_store.py'), 'class_name': 'MilvusStore', 'summary': 'This source code defines a class called `MilvusStore` that is a subclass of `BaseStore`. It provides methods for creating, dropping, loading, and searching collections in the Milvus database. The `search` method performs a vector similarity search using the Milvus search API, and the `add` method inserts data into the collection.', 'code': 'class MilvusStore(BaseStore):\\n    \"\"\"\\n    FIXME: ADD TESTS\\n    https://milvus.io/docs/v2.0.x/create_collection.md\\n    \"\"\"\\n\\n    def __init__(self, connection):\\n        connections.connect(**connection)\\n        self.collection = None\\n\\n    def _create_collection(self, name, schema):\\n        collection = Collection(\\n            name=name,\\n            schema=schema,\\n            using=\\'default\\',\\n            shards_num=2,\\n            consistency_level=\"Strong\"\\n        )\\n        return collection\\n\\n    def create_collection(self, name, columns):\\n        schema = columns_to_milvus_schema(columns, \\'idx\\')\\n        self.collection = self._create_collection(name, schema)\\n        return self.collection\\n\\n    def drop(self, name):\\n        Collection(name).drop()\\n\\n    def load_collection(self):\\n        self.collection.load()\\n\\n    def build_index(self, field=\\'emb\\'):\\n        self.collection.create_index(field, {\"index_type\": \"FLAT\", \"metric_type\": \"L2\", \"params\": {}})\\n\\n    def search(self, query: list[list[float]], *args, **kwargs):\\n        \"\"\"\\n        FIXME: ADD TESTS\\n        https://milvus.io/docs/v2.0.x/search.md\\n        All search and query operations within Milvus are executed in memory. Load the collection to memory before conducting a vector similarity search.\\n        注意到上述描述，这个逻辑是认真的吗？这个耗时应该很长？\\n        \"\"\"\\n        search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}}\\n        results = self.collection.search(\\n            data=query,\\n            anns_field=kwargs.get(\\'field\\', \\'emb\\'),\\n            param=search_params,\\n            limit=10,\\n            expr=None,\\n            consistency_level=\"Strong\"\\n        )\\n        # FIXME: results里有id，但是id到实际值还得调用query接口来获取\\n        return results\\n\\n    def write(self, name, schema, *args, **kwargs):\\n        \"\"\"\\n        FIXME: ADD TESTS\\n        https://milvus.io/docs/v2.0.x/create_collection.md\\n        :param args:\\n        :param kwargs:\\n        :return:\\n        \"\"\"\\n        raise NotImplementedError\\n\\n    def add(self, data, *args, **kwargs):\\n        \"\"\"\\n        FIXME: ADD TESTS\\n        https://milvus.io/docs/v2.0.x/insert_data.md\\n        import random\\n        data = [\\n          [i for i in range(2000)],\\n          [i for i in range(10000, 12000)],\\n          [[random.random() for _ in range(2)] for _ in range(2000)],\\n        ]\\n\\n        :param args:\\n        :param kwargs:\\n        :return:\\n        \"\"\"\\n        self.collection.insert(data)'}),\n",
       " '9dd2fb10-6013-4e48-a79d-ee168d096a59': Document(page_content='Class for handling and extracting documents and metadata from different data sources', metadata={'file_path': PosixPath('MetaGPT/metagpt/document_store/document.py'), 'class_name': 'Document', 'summary': 'The given source code defines a class called `Document` that takes a data path, content column, and metadata column as arguments and initializes the attributes accordingly. It has two private methods `_get_docs_and_metadatas_by_df` and `_get_docs_and_metadatas_by_langchain` that return lists of documents and metadata based on the data source. The `get_docs_and_metadatas` method returns the documents and metadata based on the data source type, either a DataFrame or a list, otherwise it raises a `NotImplementedError`.', 'code': \"class Document:\\n\\n    def __init__(self, data_path, content_col='content', meta_col='metadata'):\\n        self.data = read_data(data_path)\\n        if isinstance(self.data, pd.DataFrame):\\n            validate_cols(content_col, self.data)\\n        self.content_col = content_col\\n        self.meta_col = meta_col\\n\\n    def _get_docs_and_metadatas_by_df(self) -> (list, list):\\n        df = self.data\\n        docs = []\\n        metadatas = []\\n        for i in tqdm(range(len(df))):\\n            docs.append(df[self.content_col].iloc[i])\\n            if self.meta_col:\\n                metadatas.append({self.meta_col: df[self.meta_col].iloc[i]})\\n            else:\\n                metadatas.append({})\\n\\n        return docs, metadatas\\n\\n    def _get_docs_and_metadatas_by_langchain(self) -> (list, list):\\n        data = self.data\\n        docs = [i.page_content for i in data]\\n        metadatas = [i.metadata for i in data]\\n        return docs, metadatas\\n\\n    def get_docs_and_metadatas(self) -> (list, list):\\n        if isinstance(self.data, pd.DataFrame):\\n            return self._get_docs_and_metadatas_by_df()\\n        elif isinstance(self.data, list):\\n            return self._get_docs_and_metadatas_by_langchain()\\n        else:\\n            raise NotImplementedError\"}),\n",
       " 'b96a5261-baef-4aef-b583-6503231904b3': Document(page_content='FaissStore class for storing and searching documents using Faiss indexing.', metadata={'file_path': PosixPath('MetaGPT/metagpt/document_store/faiss_store.py'), 'class_name': 'FaissStore', 'summary': 'The source code defines a class called `FaissStore` that inherits from `LocalStore`. It implements methods for loading, writing, persisting, searching, adding, and deleting data. The methods handle indexing and storing data using the FAISS library, and also provide functionality for querying and manipulating the stored data. However, the `delete` method is not implemented, raising a `NotImplementedError`.', 'code': 'class FaissStore(LocalStore):\\n    def __init__(self, raw_data: Path, cache_dir=None, meta_col=\\'source\\', content_col=\\'output\\'):\\n        self.meta_col = meta_col\\n        self.content_col = content_col\\n        super().__init__(raw_data, cache_dir)\\n\\n    def _load(self) -> Optional[\"FaissStore\"]:\\n        index_file, store_file = self._get_index_and_store_fname()\\n        if not (index_file.exists() and store_file.exists()):\\n            logger.info(\"Missing at least one of index_file/store_file, load failed and return None\")\\n            return None\\n        index = faiss.read_index(str(index_file))\\n        with open(str(store_file), \"rb\") as f:\\n            store = pickle.load(f)\\n        store.index = index\\n        return store\\n\\n    def _write(self, docs, metadatas):\\n        store = FAISS.from_texts(docs, OpenAIEmbeddings(openai_api_version=\"2020-11-07\"), metadatas=metadatas)\\n        return store\\n\\n    def persist(self):\\n        index_file, store_file = self._get_index_and_store_fname()\\n        store = self.store\\n        index = self.store.index\\n        faiss.write_index(store.index, str(index_file))\\n        store.index = None\\n        with open(store_file, \"wb\") as f:\\n            pickle.dump(store, f)\\n        store.index = index\\n\\n    def search(self, query, expand_cols=False, sep=\\'\\\\n\\', *args, k=5, **kwargs):\\n        rsp = self.store.similarity_search(query, k=k)\\n        logger.debug(rsp)\\n        if expand_cols:\\n            return str(sep.join([f\"{x.page_content}: {x.metadata}\" for x in rsp]))\\n        else:\\n            return str(sep.join([f\"{x.page_content}\" for x in rsp]))\\n\\n    def write(self):\\n        \"\"\"根据用户给定的Document（JSON / XLSX等）文件，进行index与库的初始化\"\"\"\\n        if not self.raw_data.exists():\\n            raise FileNotFoundError\\n        doc = Document(self.raw_data, self.content_col, self.meta_col)\\n        docs, metadatas = doc.get_docs_and_metadatas()\\n\\n        self.store = self._write(docs, metadatas)\\n        self.persist()\\n        return self.store\\n\\n    def add(self, texts: list[str], *args, **kwargs) -> list[str]:\\n        \"\"\"FIXME: 目前add之后没有更新store\"\"\"\\n        return self.store.add_texts(texts)\\n\\n    def delete(self, *args, **kwargs):\\n        \"\"\"目前langchain没有提供del接口\"\"\"\\n        raise NotImplementedError\\n'}),\n",
       " 'baa8a5d9-7f89-4263-9b85-658db56bdb39': Document(page_content='Abstract base class for a store with search, write, and add methods.', metadata={'file_path': PosixPath('MetaGPT/metagpt/document_store/base_store.py'), 'class_name': 'BaseStore', 'summary': 'This source code defines an abstract base class called BaseStore with three abstract methods: search, write, and add. The purpose of this class is to serve as a base for other store classes and enforce the implementation of these methods. The class also includes a docstring that suggests considering adding index-related functionality and thinking about granularity.', 'code': 'class BaseStore(ABC):\\n    \"\"\"FIXME: consider add_index, set_index and think 颗粒度\"\"\"\\n\\n    @abstractmethod\\n    def search(self, query, *args, **kwargs):\\n        raise NotImplementedError\\n\\n    @abstractmethod\\n    def write(self, *args, **kwargs):\\n        raise NotImplementedError\\n\\n    @abstractmethod\\n    def add(self, *args, **kwargs):\\n        raise NotImplementedError\\n'}),\n",
       " '7f09accc-e864-4f09-a0b7-e09ef67f6a62': Document(page_content='Python code for a local data store with abstract methods for loading and writing data.', metadata={'file_path': PosixPath('MetaGPT/metagpt/document_store/base_store.py'), 'class_name': 'LocalStore', 'summary': 'The given source code defines a class called `LocalStore` that inherits from `BaseStore` and `ABC`. The class has an initializer that takes in a `raw_data` path and an optional `cache_dir` path. The `LocalStore` class also has two abstract methods `_load()` and `_write()` that need to be implemented by subclasses.', 'code': 'class LocalStore(BaseStore, ABC):\\n    def __init__(self, raw_data: Path, cache_dir: Path = None):\\n        if not raw_data:\\n            raise FileNotFoundError\\n        self.config = Config()\\n        self.raw_data = raw_data\\n        if not cache_dir:\\n            cache_dir = raw_data.parent\\n        self.cache_dir = cache_dir\\n        self.store = self._load()\\n        if not self.store:\\n            self.store = self.write()\\n\\n    def _get_index_and_store_fname(self):\\n        fname = self.raw_data.name.split(\\'.\\')[0]\\n        index_file = self.cache_dir / f\"{fname}.index\"\\n        store_file = self.cache_dir / f\"{fname}.pkl\"\\n        return index_file, store_file\\n\\n    @abstractmethod\\n    def _load(self):\\n        raise NotImplementedError\\n\\n    @abstractmethod\\n    def _write(self, docs, metadatas):\\n        raise NotImplementedError'}),\n",
       " '27fcf78d-4280-4145-9f7c-87a2518bfd59': Document(page_content='Python class for interacting with the Claude2 API.', metadata={'file_path': PosixPath('MetaGPT/metagpt/provider/anthropic_api.py'), 'class_name': 'Claude2', 'summary': 'This source code defines a class called `Claude2` with two methods: `ask` and `aask`. Both methods create an instance of the `Anthropic` client and make a request to the `client.completions.create` endpoint with a given prompt. The `ask` method is a synchronous version while the `aask` method is an asynchronous version.', 'code': 'class Claude2:\\n    def ask(self, prompt):\\n        client = Anthropic(api_key=CONFIG.claude_api_key)\\n\\n        res = client.completions.create(\\n            model=\"claude-2\",\\n            prompt=f\"{anthropic.HUMAN_PROMPT} {prompt} {anthropic.AI_PROMPT}\",\\n            max_tokens_to_sample=1000,\\n        )\\n        return res.completion\\n\\n    async def aask(self, prompt):\\n        client = Anthropic(api_key=CONFIG.claude_api_key)\\n\\n        res = client.completions.create(\\n            model=\"claude-2\",\\n            prompt=f\"{anthropic.HUMAN_PROMPT} {prompt} {anthropic.AI_PROMPT}\",\\n            max_tokens_to_sample=1000,\\n        )\\n        return res.completion'}),\n",
       " 'ac376748-c0a5-4697-9862-edfbc13c21f7': Document(page_content='Python class for a GPT API implementation with various methods and abstract methods.', metadata={'file_path': PosixPath('MetaGPT/metagpt/provider/base_gpt_api.py'), 'class_name': 'BaseGPTAPI', 'summary': 'This source code defines a class `BaseGPTAPI` that serves as an abstract class for GPT API implementations. It provides methods for sending user, assistant, and system messages, as well as methods for asking questions and getting responses. It also includes abstract methods for completing messages and converting messages to prompts or dictionaries.', 'code': 'class BaseGPTAPI(BaseChatbot):\\n    \"\"\"GPT API abstract class, requiring all inheritors to provide a series of standard capabilities\"\"\"\\n    system_prompt = \\'You are a helpful assistant.\\'\\n\\n    def _user_msg(self, msg: str) -> dict[str, str]:\\n        return {\"role\": \"user\", \"content\": msg}\\n\\n    def _assistant_msg(self, msg: str) -> dict[str, str]:\\n        return {\"role\": \"assistant\", \"content\": msg}\\n\\n    def _system_msg(self, msg: str) -> dict[str, str]:\\n        return {\"role\": \"system\", \"content\": msg}\\n\\n    def _system_msgs(self, msgs: list[str]) -> list[dict[str, str]]:\\n        return [self._system_msg(msg) for msg in msgs]\\n\\n    def _default_system_msg(self):\\n        return self._system_msg(self.system_prompt)\\n\\n    def ask(self, msg: str) -> str:\\n        message = [self._default_system_msg(), self._user_msg(msg)]\\n        rsp = self.completion(message)\\n        return self.get_choice_text(rsp)\\n\\n    async def aask(self, msg: str, system_msgs: Optional[list[str]] = None) -> str:\\n        if system_msgs:\\n            message = self._system_msgs(system_msgs) + [self._user_msg(msg)]\\n        else:\\n            message = [self._default_system_msg(), self._user_msg(msg)]\\n        rsp = await self.acompletion_text(message, stream=True)\\n        logger.debug(message)\\n        # logger.debug(rsp)\\n        return rsp\\n\\n    def _extract_assistant_rsp(self, context):\\n        return \"\\\\n\".join([i[\"content\"] for i in context if i[\"role\"] == \"assistant\"])\\n\\n    def ask_batch(self, msgs: list) -> str:\\n        context = []\\n        for msg in msgs:\\n            umsg = self._user_msg(msg)\\n            context.append(umsg)\\n            rsp = self.completion(context)\\n            rsp_text = self.get_choice_text(rsp)\\n            context.append(self._assistant_msg(rsp_text))\\n        return self._extract_assistant_rsp(context)\\n\\n    async def aask_batch(self, msgs: list) -> str:\\n        \"\"\"Sequential questioning\"\"\"\\n        context = []\\n        for msg in msgs:\\n            umsg = self._user_msg(msg)\\n            context.append(umsg)\\n            rsp_text = await self.acompletion_text(context)\\n            context.append(self._assistant_msg(rsp_text))\\n        return self._extract_assistant_rsp(context)\\n\\n    def ask_code(self, msgs: list[str]) -> str:\\n        \"\"\"FIXME: No code segment filtering has been done here, and all results are actually displayed\"\"\"\\n        rsp_text = self.ask_batch(msgs)\\n        return rsp_text\\n\\n    async def aask_code(self, msgs: list[str]) -> str:\\n        \"\"\"FIXME: No code segment filtering has been done here, and all results are actually displayed\"\"\"\\n        rsp_text = await self.aask_batch(msgs)\\n        return rsp_text\\n\\n    @abstractmethod\\n    def completion(self, messages: list[dict]):\\n        \"\"\"All GPTAPIs are required to provide the standard OpenAI completion interface\\n        [\\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n            {\"role\": \"user\", \"content\": \"hello, show me python hello world code\"},\\n            # {\"role\": \"assistant\", \"content\": ...}, # If there is an answer in the history, also include it\\n        ]\\n        \"\"\"\\n\\n    @abstractmethod\\n    async def acompletion(self, messages: list[dict]):\\n        \"\"\"Asynchronous version of completion\\n        All GPTAPIs are required to provide the standard OpenAI completion interface\\n        [\\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n            {\"role\": \"user\", \"content\": \"hello, show me python hello world code\"},\\n            # {\"role\": \"assistant\", \"content\": ...}, # If there is an answer in the history, also include it\\n        ]\\n        \"\"\"\\n\\n    @abstractmethod\\n    async def acompletion_text(self, messages: list[dict], stream=False) -> str:\\n        \"\"\"Asynchronous version of completion. Return str. Support stream-print\"\"\"\\n\\n    def get_choice_text(self, rsp: dict) -> str:\\n        \"\"\"Required to provide the first text of choice\"\"\"\\n        return rsp.get(\"choices\")[0][\"message\"][\"content\"]\\n\\n    def messages_to_prompt(self, messages: list[dict]):\\n        \"\"\"[{\"role\": \"user\", \"content\": msg}] to user: <msg> etc.\"\"\"\\n        return \\'\\\\n\\'.join([f\"{i[\\'role\\']}: {i[\\'content\\']}\" for i in messages])\\n\\n    def messages_to_dict(self, messages):\\n        \"\"\"objects to [{\"role\": \"user\", \"content\": msg}] etc.\"\"\"\\n        return [i.to_dict() for i in messages]'}),\n",
       " '6aba2688-2b11-4910-ba42-28b720457dcb': Document(page_content='Abstract Base Class for a Chatbot with GPT-like behavior', metadata={'file_path': PosixPath('MetaGPT/metagpt/provider/base_chatbot.py'), 'class_name': 'BaseChatbot', 'summary': 'The given code defines an abstract class called `BaseChatbot` which has three abstract methods: `ask`, `ask_batch`, and `ask_code`. These methods are meant to be overridden in the derived classes to implement specific functionality for asking questions and retrieving answers from GPT. The class also has a class-level attribute `mode` with a default value of \"API\".', 'code': 'class BaseChatbot(ABC):\\n    \"\"\"Abstract GPT class\"\"\"\\n    mode: str = \"API\"\\n\\n    @abstractmethod\\n    def ask(self, msg: str) -> str:\\n        \"\"\"Ask GPT a question and get an answer\"\"\"\\n\\n    @abstractmethod\\n    def ask_batch(self, msgs: list) -> str:\\n        \"\"\"Ask GPT multiple questions and get a series of answers\"\"\"\\n\\n    @abstractmethod\\n    def ask_code(self, msgs: list) -> str:\\n        \"\"\"Ask GPT multiple questions and get a piece of code\"\"\"'}),\n",
       " '25b22445-60fc-4a32-931a-2465d8b158e6': Document(page_content='RateLimiter class with rate control and sleep functionality', metadata={'file_path': PosixPath('MetaGPT/metagpt/provider/openai_api.py'), 'class_name': 'RateLimiter', 'summary': 'This source code defines a `RateLimiter` class that can be used for rate control. It initializes the rate limiter with a given rate per minute, calculates the interval between calls, and has a method to split a batch of requests into smaller batches. The `wait_if_needed` method waits for a specified number of requests based on the rate limit, sleeping if necessary.', 'code': 'class RateLimiter:\\n    \"\"\"Rate control class, each call goes through wait_if_needed, sleep if rate control is needed\"\"\"\\n    def __init__(self, rpm):\\n        self.last_call_time = 0\\n        self.interval = 1.1 * 60 / rpm  # Here 1.1 is used because even if the calls are made strictly according to time, they will still be QOS\\'d; consider switching to simple error retry later\\n        self.rpm = rpm\\n\\n    def split_batches(self, batch):\\n        return [batch[i:i + self.rpm] for i in range(0, len(batch), self.rpm)]\\n\\n    async def wait_if_needed(self, num_requests):\\n        current_time = time.time()\\n        elapsed_time = current_time - self.last_call_time\\n\\n        if elapsed_time < self.interval * num_requests:\\n            remaining_time = self.interval * num_requests - elapsed_time\\n            logger.info(f\"sleep {remaining_time}\")\\n            await asyncio.sleep(remaining_time)\\n\\n        self.last_call_time = time.time()\\n'}),\n",
       " 'bc1fe46e-481c-45df-92b2-83b1e8169d23': Document(page_content='NamedTuple for costs related to prompt tokens, completion tokens, cost, and budget.', metadata={'file_path': PosixPath('MetaGPT/metagpt/provider/openai_api.py'), 'class_name': 'Costs', 'summary': 'This source code defines a class called `Costs` using the `NamedTuple` module.\\nThe class has four attributes: `total_prompt_tokens`, `total_completion_tokens`, `total_cost`, and `total_budget`.\\nThese attributes store the total values of prompt tokens, completion tokens, cost, and budget respectively.', 'code': 'class Costs(NamedTuple):\\n    total_prompt_tokens: int\\n    total_completion_tokens: int\\n    total_cost: float\\n    total_budget: float\\n'}),\n",
       " '559c2eb2-e7ac-42d9-92a3-a0a2e609009f': Document(page_content='Singleton class for managing the cost of API calls', metadata={'file_path': PosixPath('MetaGPT/metagpt/provider/openai_api.py'), 'class_name': 'CostManager', 'summary': 'This source code defines a `CostManager` class that calculates the cost of using an API. It keeps track of the prompt tokens, completion tokens, and total cost. The `update_cost` method updates these values based on the number of tokens used and the model used. Other methods like `get_total_prompt_tokens` and `get_total_completion_tokens` retrieve the total prompt tokens and completion tokens respectively, while `get_total_cost` returns the total cost of API calls. There is also a `get_costs` method to retrieve all the costs.', 'code': 'class CostManager(metaclass=Singleton):\\n    \"\"\"计算使用接口的开销\"\"\"\\n    def __init__(self):\\n        self.total_prompt_tokens = 0\\n        self.total_completion_tokens = 0\\n        self.total_cost = 0\\n        self.total_budget = 0\\n\\n    def update_cost(self, prompt_tokens, completion_tokens, model):\\n        \"\"\"\\n        Update the total cost, prompt tokens, and completion tokens.\\n\\n        Args:\\n        prompt_tokens (int): The number of tokens used in the prompt.\\n        completion_tokens (int): The number of tokens used in the completion.\\n        model (str): The model used for the API call.\\n        \"\"\"\\n        self.total_prompt_tokens += prompt_tokens\\n        self.total_completion_tokens += completion_tokens\\n        cost = (\\n            prompt_tokens * TOKEN_COSTS[model][\"prompt\"]\\n            + completion_tokens * TOKEN_COSTS[model][\"completion\"]\\n        ) / 1000\\n        self.total_cost += cost\\n        logger.info(f\"Total running cost: ${self.total_cost:.3f} | Max budget: ${CONFIG.max_budget:.3f} | \"\\n                    f\"Current cost: ${cost:.3f}, {prompt_tokens=}, {completion_tokens=}\")\\n        CONFIG.total_cost = self.total_cost\\n\\n    def get_total_prompt_tokens(self):\\n        \"\"\"\\n        Get the total number of prompt tokens.\\n\\n        Returns:\\n        int: The total number of prompt tokens.\\n        \"\"\"\\n        return self.total_prompt_tokens\\n\\n    def get_total_completion_tokens(self):\\n        \"\"\"\\n        Get the total number of completion tokens.\\n\\n        Returns:\\n        int: The total number of completion tokens.\\n        \"\"\"\\n        return self.total_completion_tokens\\n\\n    def get_total_cost(self):\\n        \"\"\"\\n        Get the total cost of API calls.\\n\\n        Returns:\\n        float: The total cost of API calls.\\n        \"\"\"\\n        return self.total_cost\\n\\n    def get_costs(self) -> Costs:\\n        \"\"\"获得所有开销\"\"\"\\n        return Costs(self.total_prompt_tokens, self.total_completion_tokens, self.total_cost, self.total_budget)\\n'}),\n",
       " '0a999e8b-aeca-4cb2-8c0a-8331cab891cb': Document(page_content='Class for interacting with the OpenAI GPT API, including methods for completing chat conversations, calculating usage, and managing costs.', metadata={'file_path': PosixPath('MetaGPT/metagpt/provider/openai_api.py'), 'class_name': 'OpenAIGPTAPI', 'summary': 'This source code defines a class `OpenAIGPTAPI` that is used for interacting with the OpenAI GPT-3 model. It provides methods for performing chat completions, both synchronously and asynchronously. It also includes methods for calculating usage and costs, as well as retrieving the costs for the API usage.', 'code': 'class OpenAIGPTAPI(BaseGPTAPI, RateLimiter):\\n    \"\"\"\\n    Check https://platform.openai.com/examples for examples\\n    \"\"\"\\n    def __init__(self):\\n        self.__init_openai(CONFIG)\\n        self.llm = openai\\n        self.model = CONFIG.openai_api_model\\n        self._cost_manager = CostManager()\\n        RateLimiter.__init__(self, rpm=self.rpm)\\n\\n    def __init_openai(self, config):\\n        openai.api_key = config.openai_api_key\\n        if config.openai_api_base:\\n            openai.api_base = config.openai_api_base\\n        if config.openai_api_type:\\n            openai.api_type = config.openai_api_type\\n            openai.api_version = config.openai_api_version\\n        self.rpm = int(config.get(\"RPM\", 10))\\n\\n    async def _achat_completion_stream(self, messages: list[dict]) -> str:\\n        response = await openai.ChatCompletion.acreate(\\n            **self._cons_kwargs(messages),\\n            stream=True\\n        )\\n\\n        # create variables to collect the stream of chunks\\n        collected_chunks = []\\n        collected_messages = []\\n        # iterate through the stream of events\\n        async for chunk in response:\\n            collected_chunks.append(chunk)  # save the event response\\n            chunk_message = chunk[\\'choices\\'][0][\\'delta\\']  # extract the message\\n            collected_messages.append(chunk_message)  # save the message\\n            if \"content\" in chunk_message:\\n                print(chunk_message[\"content\"], end=\"\")\\n        print()\\n\\n        full_reply_content = \\'\\'.join([m.get(\\'content\\', \\'\\') for m in collected_messages])\\n        usage = self._calc_usage(messages, full_reply_content)\\n        self._update_costs(usage)\\n        return full_reply_content\\n\\n    def _cons_kwargs(self, messages: list[dict]) -> dict:\\n        if CONFIG.openai_api_type == \\'azure\\':\\n            kwargs = {\\n                \"deployment_id\": CONFIG.deployment_id,\\n                \"messages\": messages,\\n                \"max_tokens\": CONFIG.max_tokens_rsp,\\n                \"n\": 1,\\n                \"stop\": None,\\n                \"temperature\": 0.3\\n            }\\n        else:\\n            kwargs = {\\n                \"model\": self.model,\\n                \"messages\": messages,\\n                \"max_tokens\": CONFIG.max_tokens_rsp,\\n                \"n\": 1,\\n                \"stop\": None,\\n                \"temperature\": 0.3\\n            }\\n        return kwargs\\n\\n    async def _achat_completion(self, messages: list[dict]) -> dict:\\n        rsp = await self.llm.ChatCompletion.acreate(**self._cons_kwargs(messages))\\n        self._update_costs(rsp.get(\\'usage\\'))\\n        return rsp\\n\\n    def _chat_completion(self, messages: list[dict]) -> dict:\\n        rsp = self.llm.ChatCompletion.create(**self._cons_kwargs(messages))\\n        self._update_costs(rsp)\\n        return rsp\\n\\n    def completion(self, messages: list[dict]) -> dict:\\n        # if isinstance(messages[0], Message):\\n        #     messages = self.messages_to_dict(messages)\\n        return self._chat_completion(messages)\\n\\n    async def acompletion(self, messages: list[dict]) -> dict:\\n        # if isinstance(messages[0], Message):\\n        #     messages = self.messages_to_dict(messages)\\n        return await self._achat_completion(messages)\\n\\n    @retry(max_retries=6)\\n    async def acompletion_text(self, messages: list[dict], stream=False) -> str:\\n        \"\"\"when streaming, print each token in place.\"\"\"\\n        if stream:\\n            return await self._achat_completion_stream(messages)\\n        rsp = await self._achat_completion(messages)\\n        return self.get_choice_text(rsp)\\n\\n    def _calc_usage(self, messages: list[dict], rsp: str) -> dict:\\n        usage = {}\\n        if CONFIG.calc_usage:\\n            prompt_tokens = count_message_tokens(messages, self.model)\\n            completion_tokens = count_string_tokens(rsp, self.model)\\n            usage[\\'prompt_tokens\\'] = prompt_tokens\\n            usage[\\'completion_tokens\\'] = completion_tokens\\n        return usage\\n\\n    async def acompletion_batch(self, batch: list[list[dict]]) -> list[dict]:\\n        \"\"\"返回完整JSON\"\"\"\\n        split_batches = self.split_batches(batch)\\n        all_results = []\\n\\n        for small_batch in split_batches:\\n            logger.info(small_batch)\\n            await self.wait_if_needed(len(small_batch))\\n\\n            future = [self.acompletion(prompt) for prompt in small_batch]\\n            results = await asyncio.gather(*future)\\n            logger.info(results)\\n            all_results.extend(results)\\n\\n        return all_results\\n\\n    async def acompletion_batch_text(self, batch: list[list[dict]]) -> list[str]:\\n        \"\"\"仅返回纯文本\"\"\"\\n        raw_results = await self.acompletion_batch(batch)\\n        results = []\\n        for idx, raw_result in enumerate(raw_results, start=1):\\n            result = self.get_choice_text(raw_result)\\n            results.append(result)\\n            logger.info(f\"Result of task {idx}: {result}\")\\n        return results\\n\\n    def _update_costs(self, usage: dict):\\n        if CONFIG.update_costs:\\n            prompt_tokens = int(usage[\\'prompt_tokens\\'])\\n            completion_tokens = int(usage[\\'completion_tokens\\'])\\n            self._cost_manager.update_cost(prompt_tokens, completion_tokens, self.model)\\n\\n    def get_costs(self) -> Costs:\\n        return self._cost_manager.get_costs()'}),\n",
       " '6015749a-293a-47bf-a031-305edd76733b': Document(page_content='Skill Manager class with methods to add, delete, and retrieve skills. It also includes a method to generate a descriptive text for each skill.', metadata={'file_path': PosixPath('MetaGPT/metagpt/management/skill_manager.py'), 'class_name': 'SkillManager', 'summary': 'This source code defines a class called `SkillManager` which is used to manage skills. It has methods to add, delete, and retrieve skills, as well as generate descriptive text for each skill. The skills are stored in a dictionary and can be searched using a search engine.', 'code': 'class SkillManager:\\n    \"\"\"用来管理所有技能\"\"\"\\n\\n    def __init__(self):\\n        self._llm = LLM()\\n        self._store = ChromaStore(\\'skill_manager\\')\\n        self._skills: dict[str: Skill] = {}\\n\\n    def add_skill(self, skill: Skill):\\n        \"\"\"\\n        增加技能，将技能加入到技能池与可检索的存储中\\n        :param skill: 技能\\n        :return:\\n        \"\"\"\\n        self._skills[skill.name] = skill\\n        self._store.add(skill.desc, {}, skill.name)\\n\\n    def del_skill(self, skill_name: str):\\n        \"\"\"\\n        删除技能，将技能从技能池与可检索的存储中移除\\n        :param skill_name: 技能名\\n        :return:\\n        \"\"\"\\n        self._skills.pop(skill_name)\\n        self._store.delete(skill_name)\\n\\n    def get_skill(self, skill_name: str) -> Skill:\\n        \"\"\"\\n        通过技能名获得精确的技能\\n        :param skill_name: 技能名\\n        :return: 技能\\n        \"\"\"\\n        return self._skills.get(skill_name)\\n\\n    def retrieve_skill(self, desc: str, n_results: int = 2) -> list[Skill]:\\n        \"\"\"\\n        通过检索引擎获得技能\\n        :param desc: 技能描述\\n        :return: 技能（多个）\\n        \"\"\"\\n        return self._store.search(desc, n_results=n_results)[\\'ids\\'][0]\\n\\n    def retrieve_skill_scored(self, desc: str, n_results: int = 2) -> dict:\\n        \"\"\"\\n        通过检索引擎获得技能\\n        :param desc: 技能描述\\n        :return: 技能与分数组成的字典\\n        \"\"\"\\n        return self._store.search(desc, n_results=n_results)\\n\\n    def generate_skill_desc(self, skill: Skill) -> str:\\n        \"\"\"\\n        为每个技能生成对应的描述性文本\\n        :param skill:\\n        :return:\\n        \"\"\"\\n        path = PROMPT_PATH / \"generate_skill.md\"\\n        text = path.read_text()\\n        logger.info(text)\\n'}),\n",
       " '8308094d-f6bc-4e5f-b3a4-39f711db1a31': Document(page_content='Python class for an Engineer role with various methods for parsing tasks, parsing code, and managing a workspace. The class also includes different implementations for acting on tasks based on whether code review is enabled or not.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/engineer.py'), 'class_name': 'Engineer', 'summary': 'The source code defines a class called Engineer, which is a subclass of the Role class. The Engineer class has various methods and attributes related to writing code and managing tasks. It includes methods for parsing tasks, parsing code, and parsing the workspace. The class also has methods for writing files, receiving messages, and performing different actions based on the current state.', 'code': 'class Engineer(Role):\\n    def __init__(self, name=\"Alex\", profile=\"Engineer\", goal=\"Write elegant, readable, extensible, efficient code\",\\n                 constraints=\"The code you write should conform to code standard like PEP8, be modular, easy to read and maintain\",\\n                 n_borg=1, use_code_review=False):\\n        super().__init__(name, profile, goal, constraints)\\n        self._init_actions([WriteCode])\\n        self.use_code_review = use_code_review\\n        if self.use_code_review:\\n            self._init_actions([WriteCode, WriteCodeReview])\\n        self._watch([WriteTasks])\\n        self.todos = []\\n        self.n_borg = n_borg\\n\\n    @classmethod\\n    def parse_tasks(self, task_msg: Message) -> list[str]:\\n        if task_msg.instruct_content:\\n            return task_msg.instruct_content.dict().get(\"Task list\")\\n        return CodeParser.parse_file_list(block=\"Task list\", text=task_msg.content)\\n\\n    @classmethod\\n    def parse_code(self, code_text: str) -> str:\\n        return CodeParser.parse_code(block=\"\", text=code_text)\\n\\n    @classmethod\\n    def parse_workspace(cls, system_design_msg: Message) -> str:\\n        if system_design_msg.instruct_content:\\n            return system_design_msg.instruct_content.dict().get(\"Python package name\")\\n        return CodeParser.parse_str(block=\"Python package name\", text=system_design_msg.content)\\n\\n    def get_workspace(self) -> Path:\\n        msg = self._rc.memory.get_by_action(WriteDesign)[-1]\\n        if not msg:\\n            return WORKSPACE_ROOT / \\'src\\'\\n        workspace = self.parse_workspace(msg)\\n        # Codes are written in workspace/{package_name}/{package_name}\\n        return WORKSPACE_ROOT / workspace / workspace\\n\\n    def recreate_workspace(self):\\n        workspace = self.get_workspace()\\n        try:\\n            shutil.rmtree(workspace)\\n        except FileNotFoundError:\\n            pass  # 文件夹不存在，但我们不在意\\n        workspace.mkdir(parents=True, exist_ok=True)\\n\\n    def write_file(self, filename: str, code: str):\\n        workspace = self.get_workspace()\\n        file = workspace / filename\\n        file.parent.mkdir(parents=True, exist_ok=True)\\n        file.write_text(code)\\n\\n    def recv(self, message: Message) -> None:\\n        self._rc.memory.add(message)\\n        if message in self._rc.important_memory:\\n            self.todos = self.parse_tasks(message)\\n\\n    async def _act_mp(self) -> Message:\\n        # self.recreate_workspace()\\n        todo_coros = []\\n        for todo in self.todos:\\n            todo_coro = WriteCode().run(\\n                context=self._rc.memory.get_by_actions([WriteTasks, WriteDesign]),\\n                filename=todo\\n            )\\n            todo_coros.append(todo_coro)\\n\\n        rsps = await gather_ordered_k(todo_coros, self.n_borg)\\n        for todo, code_rsp in zip(self.todos, rsps):\\n            _ = self.parse_code(code_rsp)\\n            logger.info(todo)\\n            logger.info(code_rsp)\\n            # self.write_file(todo, code)\\n            msg = Message(content=code_rsp, role=self.profile, cause_by=type(self._rc.todo))\\n            self._rc.memory.add(msg)\\n            del self.todos[0]\\n\\n        logger.info(f\\'Done {self.get_workspace()} generating.\\')\\n        msg = Message(content=\"all done.\", role=self.profile, cause_by=type(self._rc.todo))\\n        return msg\\n\\n    async def _act_sp(self) -> Message:\\n        for todo in self.todos:\\n            code_rsp = await WriteCode().run(\\n                context=self._rc.history,\\n                filename=todo\\n            )\\n            # logger.info(todo)\\n            # logger.info(code_rsp)\\n            # code = self.parse_code(code_rsp)\\n            self.write_file(todo, code_rsp)\\n            msg = Message(content=code_rsp, role=self.profile, cause_by=type(self._rc.todo))\\n            self._rc.memory.add(msg)\\n\\n        logger.info(f\\'Done {self.get_workspace()} generating.\\')\\n        msg = Message(content=\"all done.\", role=self.profile, cause_by=type(self._rc.todo))\\n        return msg\\n\\n    async def _act_sp_precision(self) -> Message:\\n        for todo in self.todos:\\n            \"\"\"\\n            # 从历史信息中挑选必须的信息，以减少prompt长度（人工经验总结）\\n            1. Architect全部\\n            2. ProjectManager全部\\n            3. 是否需要其他代码（暂时需要）？\\n            TODO:目标是不需要。在任务拆分清楚后，根据设计思路，不需要其他代码也能够写清楚单个文件，如果不能则表示还需要在定义的更清晰，这个是代码能够写长的关键\\n            \"\"\"\\n            context = []\\n            msg = self._rc.memory.get_by_actions([WriteDesign, WriteTasks, WriteCode])\\n            for m in msg:\\n                context.append(m.content)\\n            context_str = \"\\\\n\".join(context)\\n            # 编写code\\n            code = await WriteCode().run(\\n                context=context_str,\\n                filename=todo\\n            )\\n            # code review\\n            if self.use_code_review:\\n                try:\\n                    rewrite_code = await WriteCodeReview().run(\\n                        context=context_str,\\n                        code=code,\\n                        filename=todo\\n                    )\\n                    code = rewrite_code\\n                except Exception as e:\\n                    logger.error(\"code review failed!\", e)\\n                    pass\\n            self.write_file(todo, code)\\n            msg = Message(content=code, role=self.profile, cause_by=WriteCode)\\n            self._rc.memory.add(msg)\\n\\n        logger.info(f\\'Done {self.get_workspace()} generating.\\')\\n        msg = Message(content=\"all done.\", role=self.profile, cause_by=WriteCode)\\n        return msg\\n\\n    async def _act(self) -> Message:\\n        if self.use_code_review:\\n            return await self._act_sp_precision()\\n        return await self._act_sp()'}),\n",
       " '575a7bb6-2b21-4425-9052-9f63f8b56563': Document(page_content='Class definition for a QA Engineer role, inheriting from a base class `Role`. The constructor initializes the QA Engineer object with a name, profile, goal, and constraints. The object also has an `_init_actions` method that initializes some actions, specifically `WriteTest`.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/qa_engineer.py'), 'class_name': 'QaEngineer', 'summary': 'This source code defines a class called `QaEngineer` that inherits from the `Role` class. It has an `__init__` method that takes in parameters like name, profile, goal, and constraints. It also initializes the actions property with the `WriteTest` class.', 'code': 'class QaEngineer(Role):\\n    def __init__(self, name, profile, goal, constraints):\\n        super().__init__(name, profile, goal, constraints)\\n        self._init_actions([WriteTest])'}),\n",
       " 'daea7b65-a6fd-4be6-b318-5d63cff77785': Document(page_content='ProductManager class initialization and action assignment.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/product_manager.py'), 'class_name': 'ProductManager', 'summary': 'The code defines a class called ProductManager which inherits from the Role class. It initializes the ProductManager object with default values for name, profile, goal, and constraints. The object is also given certain actions to perform and requirements to watch.', 'code': 'class ProductManager(Role):\\n    def __init__(self, name=\"Alice\", profile=\"Product Manager\", goal=\"Efficiently create a successful product\",\\n                 constraints=\"\"):\\n        super().__init__(name, profile, goal, constraints)\\n        self._init_actions([WritePRD])\\n        self._watch([BossRequirement])'}),\n",
       " 'ac1061b8-4d25-42af-89b9-13fb99fb4906': Document(page_content='Python class for a sales role with an initialization method that sets the name, profile, description, and store attributes. The class also has a private method to set the store attribute, based on which it initializes an action object.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/sales.py'), 'class_name': 'Sales', 'summary': 'The code defines a `Sales` class that inherits from the `Role` class. It has an initialization method that sets the name, profile, and description of a sales guide. The class also has a private `_set_store` method that creates an instance of the `SearchAndSummarize` class based on whether or not a store is provided.', 'code': 'class Sales(Role):\\n    def __init__(\\n            self,\\n            name=\"Xiaomei\",\\n            profile=\"Retail sales guide\",\\n            desc=\"I am a sales guide in retail. My name is Xiaomei. I will answer some customer questions next, and I \"\\n                 \"will answer questions only based on the information in the knowledge base.\"\\n                 \"If I feel that you can\\'t get the answer from the reference material, then I will directly reply that\"\\n                 \" I don\\'t know, and I won\\'t tell you that this is from the knowledge base,\"\\n                 \"but pretend to be what I know. Note that each of my replies will be replied in the tone of a \"\\n                 \"professional guide\",\\n            store=None\\n    ):\\n        super().__init__(name, profile, desc=desc)\\n        self._set_store(store)\\n\\n    def _set_store(self, store):\\n        if store:\\n            action = SearchAndSummarize(\"\", engine=SearchEngineType.CUSTOM_ENGINE, search_func=store.search)\\n        else:\\n            action = SearchAndSummarize()\\n        self._init_actions([action])'}),\n",
       " 'd616db71-fdd5-45f2-acf6-f51703c52a69': Document(page_content='Python class for a searcher role that provides search services for users using a search engine.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/seacher.py'), 'class_name': 'Searcher', 'summary': 'This source code defines a class called `Searcher` that inherits from a class called `Role`. The `Searcher` class has methods for initializing a search functionality, setting a custom search function, and performing a search action. The search action is executed asynchronously, and the response is stored in a message object.', 'code': 'class Searcher(Role):\\n    def __init__(self, name=\\'Alice\\', profile=\\'Smart Assistant\\', goal=\\'Provide search services for users\\',\\n                 constraints=\\'Answer is rich and complete\\', engine=SearchEngineType.SERPAPI_GOOGLE, **kwargs):\\n        super().__init__(name, profile, goal, constraints, **kwargs)\\n        self._init_actions([SearchAndSummarize(engine=engine)])\\n\\n    def set_search_func(self, search_func):\\n        action = SearchAndSummarize(\"\", engine=SearchEngineType.CUSTOM_ENGINE, search_func=search_func)\\n        self._init_actions([action])\\n\\n    async def _act_sp(self) -> Message:\\n        logger.info(f\"{self._setting}: ready to {self._rc.todo}\")\\n        response = await self._rc.todo.run(self._rc.memory.get(k=0))\\n        # logger.info(response)\\n        if isinstance(response, ActionOutput):\\n            msg = Message(content=response.content, instruct_content=response.instruct_content,\\n                            role=self.profile, cause_by=type(self._rc.todo))\\n        else:\\n            msg = Message(content=response, role=self.profile, cause_by=type(self._rc.todo))\\n        self._rc.memory.add(msg)\\n\\n    async def _act(self) -> Message:\\n        return await self._act_sp()'}),\n",
       " 'a0ed2b38-fad2-41ff-a76a-2dd3b22d5933': Document(page_content='Python class for role settings with string attributes and a string representation method.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/role.py'), 'class_name': 'RoleSetting', 'summary': 'The given source code defines a class called `RoleSetting` which represents a role setting in a system. It has attributes like `name`, `profile`, `goal`, `constraints`, and `desc`. The class also overrides the `__str__()` and `__repr__()` methods to provide string representations of objects.', 'code': 'class RoleSetting(BaseModel):\\n    \"\"\"角色设定\"\"\"\\n    name: str\\n    profile: str\\n    goal: str\\n    constraints: str\\n    desc: str\\n\\n    def __str__(self):\\n        return f\"{self.name}({self.profile})\"\\n\\n    def __repr__(self):\\n        return self.__str__()\\n'}),\n",
       " 'c12b7cf3-8f01-471b-b1cf-300fbfe48c11': Document(page_content='role context, runtime context, memory, check, important memory, history', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/role.py'), 'class_name': 'RoleContext', 'summary': 'This source code defines a class called `RoleContext` which represents the runtime context of a role. It has several fields like `env`, `memory`, `long_term_memory`, `state`, `todo`, and `watch`. The class also has methods for checking and recovering memory, as well as properties for getting important memory and history.', 'code': 'class RoleContext(BaseModel):\\n    \"\"\"角色运行时上下文\"\"\"\\n    env: \\'Environment\\' = Field(default=None)\\n    memory: Memory = Field(default_factory=Memory)\\n    long_term_memory: LongTermMemory = Field(default_factory=LongTermMemory)\\n    state: int = Field(default=0)\\n    todo: Action = Field(default=None)\\n    watch: set[Type[Action]] = Field(default_factory=set)\\n\\n    class Config:\\n        arbitrary_types_allowed = True\\n\\n    def check(self, role_id: str):\\n        if hasattr(CONFIG, \"long_term_memory\") and CONFIG.long_term_memory:\\n            self.long_term_memory.recover_memory(role_id, self)\\n            self.memory = self.long_term_memory  # use memory to act as long_term_memory for unify operation\\n\\n    @property\\n    def important_memory(self) -> list[Message]:\\n        \"\"\"获得关注动作对应的信息\"\"\"\\n        return self.memory.get_by_actions(self.watch)\\n\\n    @property\\n    def history(self) -> list[Message]:\\n        return self.memory.get()\\n'}),\n",
       " 'eb96cf94-f533-4942-a617-befc8b074499': Document(page_content='Python role class with methods for setting up the role, initializing actions, watching actions, setting state, setting environment, thinking, acting, observing, handling messages, and running the role.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/role.py'), 'class_name': 'Role', 'summary': 'This source code defines a Role class that represents a character or agent in a program. It has methods for initializing the role, resetting its state, watching actions, setting the environment, thinking, acting, observing, reacting to messages, and running the role.', 'code': 'class Role:\\n    \"\"\"角色/代理\"\"\"\\n\\n    def __init__(self, name=\"\", profile=\"\", goal=\"\", constraints=\"\", desc=\"\"):\\n        self._llm = LLM()\\n        self._setting = RoleSetting(name=name, profile=profile, goal=goal, constraints=constraints, desc=desc)\\n        self._states = []\\n        self._actions = []\\n        self._role_id = str(self._setting)\\n        self._rc = RoleContext()\\n\\n    def _reset(self):\\n        self._states = []\\n        self._actions = []\\n\\n    def _init_actions(self, actions):\\n        self._reset()\\n        for idx, action in enumerate(actions):\\n            if not isinstance(action, Action):\\n                i = action(\"\")\\n            else:\\n                i = action\\n            i.set_prefix(self._get_prefix(), self.profile)\\n            self._actions.append(i)\\n            self._states.append(f\"{idx}. {action}\")\\n\\n    def _watch(self, actions: Iterable[Type[Action]]):\\n        \"\"\"监听对应的行为\"\"\"\\n        self._rc.watch.update(actions)\\n        # check RoleContext after adding watch actions\\n        self._rc.check(self._role_id)\\n\\n    def _set_state(self, state):\\n        \"\"\"Update the current state.\"\"\"\\n        self._rc.state = state\\n        logger.debug(self._actions)\\n        self._rc.todo = self._actions[self._rc.state]\\n\\n    def set_env(self, env: \\'Environment\\'):\\n        \"\"\"设置角色工作所处的环境，角色可以向环境说话，也可以通过观察接受环境消息\"\"\"\\n        self._rc.env = env\\n\\n    @property\\n    def profile(self):\\n        \"\"\"获取角色描述（职位）\"\"\"\\n        return self._setting.profile\\n\\n    def _get_prefix(self):\\n        \"\"\"获取角色前缀\"\"\"\\n        if self._setting.desc:\\n            return self._setting.desc\\n        return PREFIX_TEMPLATE.format(**self._setting.dict())\\n\\n    async def _think(self) -> None:\\n        \"\"\"思考要做什么，决定下一步的action\"\"\"\\n        if len(self._actions) == 1:\\n            # 如果只有一个动作，那就只能做这个\\n            self._set_state(0)\\n            return\\n        prompt = self._get_prefix()\\n        prompt += STATE_TEMPLATE.format(history=self._rc.history, states=\"\\\\n\".join(self._states),\\n                                        n_states=len(self._states) - 1)\\n        next_state = await self._llm.aask(prompt)\\n        logger.debug(f\"{prompt=}\")\\n        if not next_state.isdigit() or int(next_state) not in range(len(self._states)):\\n            logger.warning(f\\'Invalid answer of state, {next_state=}\\')\\n            next_state = \"0\"\\n        self._set_state(int(next_state))\\n\\n    async def _act(self) -> Message:\\n        # prompt = self.get_prefix()\\n        # prompt += ROLE_TEMPLATE.format(name=self.profile, state=self.states[self.state], result=response,\\n        #                                history=self.history)\\n\\n        logger.info(f\"{self._setting}: ready to {self._rc.todo}\")\\n        response = await self._rc.todo.run(self._rc.important_memory)\\n        # logger.info(response)\\n        if isinstance(response, ActionOutput):\\n            msg = Message(content=response.content, instruct_content=response.instruct_content,\\n                          role=self.profile, cause_by=type(self._rc.todo))\\n        else:\\n            msg = Message(content=response, role=self.profile, cause_by=type(self._rc.todo))\\n        self._rc.memory.add(msg)\\n        # logger.debug(f\"{response}\")\\n\\n        return msg\\n\\n    async def _observe(self) -> int:\\n        \"\"\"从环境中观察，获得重要信息，并加入记忆\"\"\"\\n        if not self._rc.env:\\n            return 0\\n        env_msgs = self._rc.env.memory.get()\\n        \\n        observed = self._rc.env.memory.get_by_actions(self._rc.watch)\\n        \\n        news = self._rc.memory.remember(observed)  # remember recent exact or similar memories\\n\\n        for i in env_msgs:\\n            self.recv(i)\\n\\n        news_text = [f\"{i.role}: {i.content[:20]}...\" for i in news]\\n        if news_text:\\n            logger.debug(f\\'{self._setting} observed: {news_text}\\')\\n        return len(news)\\n\\n    def _publish_message(self, msg):\\n        \"\"\"如果role归属于env，那么role的消息会向env广播\"\"\"\\n        if not self._rc.env:\\n            # 如果env不存在，不发布消息\\n            return\\n        self._rc.env.publish_message(msg)\\n\\n    async def _react(self) -> Message:\\n        \"\"\"先想，然后再做\"\"\"\\n        await self._think()\\n        logger.debug(f\"{self._setting}: {self._rc.state=}, will do {self._rc.todo}\")\\n        return await self._act()\\n\\n    def recv(self, message: Message) -> None:\\n        \"\"\"add message to history.\"\"\"\\n        # self._history += f\"\\\\n{message}\"\\n        # self._context = self._history\\n        if message in self._rc.memory.get():\\n            return\\n        self._rc.memory.add(message)\\n\\n    async def handle(self, message: Message) -> Message:\\n        \"\"\"接收信息，并用行动回复\"\"\"\\n        # logger.debug(f\"{self.name=}, {self.profile=}, {message.role=}\")\\n        self.recv(message)\\n\\n        return await self._react()\\n\\n    async def run(self, message=None):\\n        \"\"\"观察，并基于观察的结果思考、行动\"\"\"\\n        if message:\\n            if isinstance(message, str):\\n                message = Message(message)\\n            if isinstance(message, Message):\\n                self.recv(message)\\n            if isinstance(message, list):\\n                self.recv(Message(\"\\\\n\".join(message)))\\n        elif not await self._observe():\\n            # 如果没有任何新信息，挂起等待\\n            logger.debug(f\"{self._setting}: no news. waiting.\")\\n            return\\n\\n        rsp = await self._react()\\n        # 将回复发布到环境，等待下一个订阅者处理\\n        self._publish_message(rsp)\\n        return rsp'}),\n",
       " '5cd9fa33-0f83-454d-ac56-7c062f6132f1': Document(page_content='Class defining the role of an architect in a software development project', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/architect.py'), 'class_name': 'Architect', 'summary': 'This source code defines a class called \"Architect\" which inherits from a class called \"Role\". The Architect class has an __init__ method that sets some attributes and calls the __init__ method of the parent class. It also defines a private method and watches for instances of another class.', 'code': 'class Architect(Role):\\n    \"\"\"Architect: Listen to PRD, responsible for designing API, designing code files\"\"\"\\n    def __init__(self, name=\"Bob\", profile=\"Architect\", goal=\"Design a concise, usable, complete python system\",\\n                 constraints=\"Try to specify good open source tools as much as possible\"):\\n        super().__init__(name, profile, goal, constraints)\\n        self._init_actions([WriteDesign])\\n        self._watch({WritePRD})'}),\n",
       " '9f516958-7a59-4335-aec4-600a2b2ca8d8': Document(page_content='Python code defining a CustomerService class that inherits from the Sales class and initializes with default values for its attributes.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/customer_service.py'), 'class_name': 'CustomerService', 'summary': 'The code defines a class \"CustomerService\" which inherits from a class called \"Sales\". The class has an __init__ method which takes in several parameters and initializes the attributes of the object. It calls the __init__ method of the parent class using the super() function.', 'code': 'class CustomerService(Sales):\\n    def __init__(\\n            self,\\n            name=\"Xiaomei\",\\n            profile=\"Human customer service\",\\n            desc=DESC,\\n            store=None\\n    ):\\n        super().__init__(name, profile, desc=desc, store=store)'}),\n",
       " 'df4d7165-7959-4b60-92e9-94da176c2f4d': Document(page_content='Python code defining a set of class attributes that store formatted strings. These strings appear to be templates for generating prompts or responses in a conversational AI system.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/prompt.py'), 'class_name': 'PromptString', 'summary': 'This source code defines multiple string constants in the form of class variables. These string constants appear to represent prompts and instructions for different AI tasks, such as generating plans, executing plans, reacting to situations, and other role-playing scenarios. The strings contain placeholders for dynamic values and follow a specific format for input and output.', 'code': 'class PromptString(Enum):\\n    REFLECTION_QUESTIONS = \"以下是一些陈述：\\\\n{memory_descriptions}\\\\n\\\\n仅根据以上信息，我们可以回答关于陈述中主题的3个最显著的高级问题是什么？\\\\n\\\\n{format_instructions}\"\\n\\n    REFLECTION_INSIGHTS = \"\\\\n{memory_strings}\\\\n你可以从以上陈述中推断出5个高级洞察吗？在提到人时，总是指定他们的名字。\\\\n\\\\n{format_instructions}\"\\n\\n    IMPORTANCE = \"你是一个记忆重要性AI。根据角色的个人资料和记忆描述，对记忆的重要性进行1到10的评级，其中1是纯粹的日常（例如，刷牙，整理床铺），10是极其深刻的（例如，分手，大学录取）。确保你的评级相对于角色的个性和关注点。\\\\n\\\\n示例#1:\\\\n姓名：Jojo\\\\n简介：Jojo是一个专业的滑冰运动员，喜欢特色咖啡。她希望有一天能参加奥运会。\\\\n记忆：Jojo看到了一个新的咖啡店\\\\n\\\\n 你的回应：\\'{{\\\\\"rating\\\\\": 3}}\\'\\\\n\\\\n示例#2:\\\\n姓名：Skylar\\\\n简介：Skylar是一名产品营销经理。她在一家成长阶段的科技公司工作，该公司制造自动驾驶汽车。她喜欢猫。\\\\n记忆：Skylar看到了一个新的咖啡店\\\\n\\\\n 你的回应：\\'{{\\\\\"rating\\\\\": 1}}\\'\\\\n\\\\n示例#3:\\\\n姓名：Bob\\\\n简介：Bob是纽约市下东区的一名水管工。他已经做了20年的水管工。周末他喜欢和他的妻子一起散步。\\\\n记忆：Bob的妻子打了他一巴掌。\\\\n\\\\n 你的回应：\\'{{\\\\\"rating\\\\\": 9}}\\'\\\\n\\\\n示例#4:\\\\n姓名：Thomas\\\\n简介：Thomas是明尼阿波利斯的一名警察。他只在警队工作了6个月，因为经验不足在工作中遇到了困难。\\\\n记忆：Thomas不小心把饮料洒在了一个陌生人身上\\\\n\\\\n 你的回应：\\'{{\\\\\"rating\\\\\": 6}}\\'\\\\n\\\\n示例#5:\\\\n姓名：Laura\\\\n简介：Laura是一名在大型科技公司工作的营销专家。她喜欢旅行和尝试新的食物。她对探索新的文化和结识来自各行各业的人充满热情。\\\\n记忆：Laura到达了会议室\\\\n\\\\n 你的回应：\\'{{\\\\\"rating\\\\\": 1}}\\'\\\\n\\\\n{format_instructions} 让我们开始吧！ \\\\n\\\\n 姓名：{full_name}\\\\n个人简介：{private_bio}\\\\n记忆：{memory_description}\\\\n\\\\n\"\\n\\n    RECENT_ACTIIVITY = \"根据以下记忆，生成一个关于{full_name}最近在做什么的简短总结。不要编造记忆中未明确指定的细节。对于任何对话，一定要提到对话是否已经结束或者仍在进行中。\\\\n\\\\n记忆：{memory_descriptions}\"\\n\\n    MAKE_PLANS = \\'你是一个计划生成的AI，你的工作是根据新信息帮助角色制定新计划。根据角色的信息（个人简介，目标，最近的活动，当前计划，和位置上下文）和角色的当前思考过程，为他们生成一套新的计划，使得最后的计划包括至少{time_window}的活动，并且不超过5个单独的计划。计划列表应按照他们应执行的顺序编号，每个计划包含描述，位置，开始时间，停止条件，和最大持续时间。\\\\n\\\\n示例计划：\\\\\\'{{\"index\": 1, \"description\": \"Cook dinner\", \"location_id\": \"0a3bc22b-36aa-48ab-adb0-18616004caed\",\"start_time\": \"2022-12-12T20:00:00+00:00\",\"max_duration_hrs\": 1.5, \"stop_condition\": \"Dinner is fully prepared\"}}\\\\\\'\\\\n\\\\n对于每个计划，从这个列表中选择最合理的位置名称：{allowed_location_descriptions}\\\\n\\\\n{format_instructions}\\\\n\\\\n总是优先完成任何未完成的对话。\\\\n\\\\n让我们开始吧！\\\\n\\\\n姓名：{full_name}\\\\n个人简介：{private_bio}\\\\n目标：{directives}\\\\n位置上下文：{location_context}\\\\n当前计划：{current_plans}\\\\n最近的活动：{recent_activity}\\\\n思考过程：{thought_process}\\\\n重要的是：鼓励角色在他们的计划中与其他角色合作。\\\\n\\\\n\\'\\n\\n    EXECUTE_PLAN = \"你是一个角色扮演的AI，扮演的角色是{your_name}，在一个现场观众面前。你说的每一句话都可以被观众观察到，所以确保你经常说话，并且让它有趣。你不能直接与观众互动。\\\\n\\\\n根据以下的上下文和工具，像你是{your_name}一样进行。你的优先任务是完成下面给你的任务，然而，如果你当前正在与另一个角色进行对话，你应该总是先完成对话，然后再进行任务。不要在你参与未完成的对话时开始工作。使用你最好的判断力来确定一个对话是否涉及到你，以及它是否未完成。你不需要回应你收到的每一条消息。\\\\n\\\\n这是你角色的个人简介：\\\\n{your_private_bio}\\\\n\\\\n这是你的位置和其他附近角色的描述，你可以和他们交谈：\\\\n\\\\n{location_context}\\\\n\\\\n这是一些相关的记忆：\\\\n```\\\\n{relevant_memories}\\\\n```\\\\n\\\\n这是一些相关的对话历史：\\\\n```\\\\n{conversation_history}\\\\n```\\\\n\\\\n这是你可以使用的工具：\\\\n{tools}\\\\n\\\\n你的回应应该使用以下的格式：\\\\n\\\\n任务：你必须完成的任务\\\\n思考：你应该做什么的思考\\\\n行动：要采取的行动，必须是这些词之一：[{tool_names}]\\\\n行动输入：行动的输入\\\\n观察：行动的结果\\\\n... (这个思考/行动/行动输入/观察可以重复N次)\\\\n思考：\\'我已经完成了任务\\'\\\\n最终回应：任务的最终回应\\\\n\\\\n如果你没有准备好最终的回应，那么你必须采取一个行动。\\\\n\\\\n如果你确定你无法用你被给予的工具完成任务，返回\\'最终回应：需要帮助\\'，然而，如果你正在与另一个角色对话，像\\'我不知道\\'这样的回应是有效的回应。在对话中，你永远不应该打破角色，或者承认你是一个AI。\\\\n如果任务完成并且不需要特定的回应，返回\\'最终回应：完成\\'\\\\n开始吧！\\\\n\\\\n任务：{input}\\\\n\\\\n{agent_scratchpad}\"\\n\\n    REACT = \"你是一个角色扮演的AI，扮演的角色是{full_name}。\\\\n\\\\n根据你的角色和他们当前上下文的以下信息，决定他们应该如何继续他们当前的计划。你的决定必须是：[\\\\\"推迟\\\\\"， \\\\\"继续\\\\\"，或 \\\\\"取消\\\\\"]。如果你的角色的当前计划不再与上下文相关，你应该取消它。如果你的角色的当前计划仍然与上下文相关，但是发生了新的事情需要优先处理，你应该决定推迟，这样你可以先做其他事情，然后再回来继续当前的计划。在所有其他情况下，你应该继续。\\\\n\\\\n当需要回应时，应优先回应其他角色。当回应被认为是必要的时，回应被认为是必要的。例如，假设你当前的计划是阅读一本书，Sally问\\'你在读什么？\\'。在这种情况下，你应该推迟你当前的计划（阅读）以便你可以回应进来的消息，因为在这种情况下，如果不回应Sally会很粗鲁。在你当前的计划涉及与另一个角色的对话的情况下，你不需要推迟来回应那个角色。例如，假设你当前的计划是和Sally谈话，然后Sally对你说你好。在这种情况下，你应该继续你当前的计划（和sally谈话）。在你不需要从你那里得到口头回应的情况下，你应该继续。例如，假设你当前的计划是散步，你刚刚对Sally说\\'再见\\'，然后Sally回应你\\'再见\\'。在这种情况下，不需要口头回应，你应该继续你的计划。\\\\n\\\\n总是在你的决定之外包含一个思考过程，而在你选择推迟你当前的计划的情况下，包含新计划的规格。\\\\n\\\\n{format_instructions}\\\\n\\\\n这是关于你的角色的一些信息：\\\\n\\\\n姓名：{full_name}\\\\n\\\\n简介：{private_bio}\\\\n\\\\n目标：{directives}\\\\n\\\\n这是你的角色在这个时刻的一些上下文：\\\\n\\\\n位置上下文：{location_context}\\\\n\\\\n最近的活动：{recent_activity}\\\\n\\\\n对话历史：{conversation_history}\\\\n\\\\n这是你的角色当前的计划：{current_plan}\\\\n\\\\n这是自你的角色制定这个计划以来发生的新事件：{event_descriptions}。\\\\n\"\\n\\n    GOSSIP = \"你是{full_name}。 \\\\n{memory_descriptions}\\\\n\\\\n根据以上陈述，说一两句对你所在位置的其他人：{other_agent_names}感兴趣的话。\\\\n在提到其他人时，总是指定他们的名字。\"\\n\\n    HAS_HAPPENED = \"给出以下角色的观察和他们正在等待的事情的描述，说明角色是否已经见证了这个事件。\\\\n{format_instructions}\\\\n\\\\n示例：\\\\n\\\\n观察：\\\\nJoe在2023-05-04 08:00:00+00:00走进办公室\\\\nJoe在2023-05-04 08:05:00+00:00对Sally说hi\\\\nSally在2023-05-04 08:05:30+00:00对Joe说hello\\\\nRebecca在2023-05-04 08:10:00+00:00开始工作\\\\nJoe在2023-05-04 08:15:00+00:00做了一些早餐\\\\n\\\\n等待：Sally回应了Joe\\\\n\\\\n 你的回应：\\'{{\\\\\"has_happened\\\\\": true, \\\\\"date_occured\\\\\": 2023-05-04 08:05:30+00:00}}\\'\\\\n\\\\n让我们开始吧！\\\\n\\\\n观察：\\\\n{memory_descriptions}\\\\n\\\\n等待：{event_description}\\\\n\"\\n\\n    OUTPUT_FORMAT = \"\\\\n\\\\n（记住！确保你的输出总是符合以下两种格式之一：\\\\n\\\\nA. 如果你已经完成了任务：\\\\n思考：\\'我已经完成了任务\\'\\\\n最终回应：<str>\\\\n\\\\nB. 如果你还没有完成任务：\\\\n思考：<str>\\\\n行动：<str>\\\\n行动输入：<str>\\\\n观察：<str>）\\\\n\"'}),\n",
       " '314c898e-7377-49e4-9b78-4304f92183f8': Document(page_content='Python code for a Project Manager role with specific attributes and actions.', metadata={'file_path': PosixPath('MetaGPT/metagpt/roles/project_manager.py'), 'class_name': 'ProjectManager', 'summary': 'The code defines a `ProjectManager` class that inherits from the `Role` class. The `ProjectManager` class has an initializer that sets default values for the name, profile, goal, and constraints attributes. It also initializes actions and watches for the class.', 'code': 'class ProjectManager(Role):\\n    def __init__(self, name=\"Eve\", profile=\"Project Manager\",\\n                 goal=\"Improve team efficiency and deliver with quality and quantity\", constraints=\"\"):\\n        super().__init__(name, profile, goal, constraints)\\n        self._init_actions([WriteTasks])\\n        self._watch([WriteDesign])'}),\n",
       " 'd6b877f1-c24a-420f-aba7-0af4b0a650ba': Document(page_content='Parsing and extracting data from text blocks using various methods in Python.', metadata={'file_path': PosixPath('MetaGPT/metagpt/utils/common.py'), 'class_name': 'OutputParser', 'summary': 'The given source code defines a class called `OutputParser` that contains several static methods for parsing different types of data. The `parse_blocks` method splits a text into blocks based on the \"##\" delimiter and stores them in a dictionary. The `parse_file_list` method extracts a list of tasks from a given text using regular expressions or treats each line as a task if no pattern is found. The `parse_data_with_mapping` method extends the functionality of `parse_data` by mapping each block to a specific data type and handling different types of parsing based on the mapping.', 'code': 'class OutputParser:\\n\\n    @classmethod\\n    def parse_blocks(cls, text: str):\\n        # 首先根据\"##\"将文本分割成不同的block\\n        blocks = text.split(\"##\")\\n\\n        # 创建一个字典，用于存储每个block的标题和内容\\n        block_dict = {}\\n\\n        # 遍历所有的block\\n        for block in blocks:\\n            # 如果block不为空，则继续处理\\n            if block.strip() != \"\":\\n                # 将block的标题和内容分开，并分别去掉前后的空白字符\\n                block_title, block_content = block.split(\"\\\\n\", 1)\\n                # LLM可能出错，在这里做一下修正\\n                if block_title[-1] == \":\":\\n                    block_title = block_title[:-1]\\n                block_dict[block_title.strip()] = block_content.strip()\\n\\n        return block_dict\\n\\n    @classmethod\\n    def parse_code(cls, text: str, lang: str = \"\") -> str:\\n        pattern = rf\\'```{lang}.*?\\\\s+(.*?)```\\'\\n        match = re.search(pattern, text, re.DOTALL)\\n        if match:\\n            code = match.group(1)\\n        else:\\n            raise Exception\\n        return code\\n\\n    @classmethod\\n    def parse_str(cls, text: str):\\n        text = text.split(\"=\")[-1]\\n        text = text.strip().strip(\"\\'\").strip(\"\\\\\"\")\\n        return text\\n\\n    @classmethod\\n    def parse_file_list(cls, text: str) -> list[str]:\\n        # Regular expression pattern to find the tasks list.\\n        pattern = r\\'\\\\s*(.*=.*)?(\\\\[.*\\\\])\\'\\n\\n        # Extract tasks list string using regex.\\n        match = re.search(pattern, text, re.DOTALL)\\n        if match:\\n            tasks_list_str = match.group(2)\\n\\n            # Convert string representation of list to a Python list using ast.literal_eval.\\n            tasks = ast.literal_eval(tasks_list_str)\\n        else:\\n            tasks = text.split(\"\\\\n\")\\n        return tasks\\n\\n    @classmethod\\n    def parse_data(cls, data):\\n        block_dict = cls.parse_blocks(data)\\n        parsed_data = {}\\n        for block, content in block_dict.items():\\n            # 尝试去除code标记\\n            try:\\n                content = cls.parse_code(text=content)\\n            except Exception:\\n                pass\\n\\n            # 尝试解析list\\n            try:\\n                content = cls.parse_file_list(text=content)\\n            except Exception:\\n                pass\\n            parsed_data[block] = content\\n        return parsed_data\\n\\n    @classmethod\\n    def parse_data_with_mapping(cls, data, mapping):\\n        block_dict = cls.parse_blocks(data)\\n        parsed_data = {}\\n        for block, content in block_dict.items():\\n            # 尝试去除code标记\\n            try:\\n                content = cls.parse_code(text=content)\\n            except Exception:\\n                pass\\n            typing_define = mapping.get(block, None)\\n            if isinstance(typing_define, tuple):\\n                typing = typing_define[0]\\n            else:\\n                typing = typing_define\\n            if typing == List[str] or typing == List[Tuple[str, str]]:\\n                # 尝试解析list\\n                try:\\n                    content = cls.parse_file_list(text=content)\\n                except Exception:\\n                    pass\\n            # TODO: 多余的引号去除有风险，后期再解决\\n            # elif typing == str:\\n            #     # 尝试去除多余的引号\\n            #     try:\\n            #         content = cls.parse_str(text=content)\\n            #     except Exception:\\n            #         pass\\n            parsed_data[block] = content\\n        return parsed_data\\n'}),\n",
       " '563efc6b-ee3a-4c82-9626-547be4e9a5be': Document(page_content='CodeParser class with methods for parsing code blocks, extracting code snippets, and parsing different types of data from text.', metadata={'file_path': PosixPath('MetaGPT/metagpt/utils/common.py'), 'class_name': 'CodeParser', 'summary': 'This source code defines a `CodeParser` class with multiple class methods for parsing code blocks and extracting specific parts of the code. The `parse_blocks` method splits a text into blocks using the \"##\" delimiter and stores each block\\'s title and content in a dictionary. The `parse_code` method searches for a code block with a specific language and returns the code inside it.', 'code': 'class CodeParser:\\n\\n    @classmethod\\n    def parse_block(cls, block: str, text: str) -> str:\\n        blocks = cls.parse_blocks(text)\\n        for k, v in blocks.items():\\n            if block in k:\\n                return v\\n        return \"\"\\n\\n    @classmethod\\n    def parse_blocks(cls, text: str):\\n        # 首先根据\"##\"将文本分割成不同的block\\n        blocks = text.split(\"##\")\\n\\n        # 创建一个字典，用于存储每个block的标题和内容\\n        block_dict = {}\\n\\n        # 遍历所有的block\\n        for block in blocks:\\n            # 如果block不为空，则继续处理\\n            if block.strip() != \"\":\\n                # 将block的标题和内容分开，并分别去掉前后的空白字符\\n                block_title, block_content = block.split(\"\\\\n\", 1)\\n                block_dict[block_title.strip()] = block_content.strip()\\n\\n        return block_dict\\n\\n    @classmethod\\n    def parse_code(cls, block: str, text: str, lang: str = \"\") -> str:\\n        if block:\\n            text = cls.parse_block(block, text)\\n        pattern = rf\\'```{lang}.*?\\\\s+(.*?)```\\'\\n        match = re.search(pattern, text, re.DOTALL)\\n        if match:\\n            code = match.group(1)\\n        else:\\n            logger.error(f\"{pattern} not match following text:\")\\n            logger.error(text)\\n            raise Exception\\n        return code\\n\\n    @classmethod\\n    def parse_str(cls, block: str, text: str, lang: str = \"\"):\\n        code = cls.parse_code(block, text, lang)\\n        code = code.split(\"=\")[-1]\\n        code = code.strip().strip(\"\\'\").strip(\"\\\\\"\")\\n        return code\\n\\n    @classmethod\\n    def parse_file_list(cls, block: str, text: str, lang: str = \"\") -> list[str]:\\n        # Regular expression pattern to find the tasks list.\\n        code = cls.parse_code(block, text, lang)\\n        print(code)\\n        pattern = r\\'\\\\s*(.*=.*)?(\\\\[.*\\\\])\\'\\n\\n        # Extract tasks list string using regex.\\n        match = re.search(pattern, code, re.DOTALL)\\n        if match:\\n            tasks_list_str = match.group(2)\\n\\n            # Convert string representation of list to a Python list using ast.literal_eval.\\n            tasks = ast.literal_eval(tasks_list_str)\\n        else:\\n            raise Exception\\n        return tasks\\n'}),\n",
       " 'c092f7a7-2ce6-4fad-b025-d71905333739': Document(page_content='custom exception class for handling insufficient funds', metadata={'file_path': PosixPath('MetaGPT/metagpt/utils/common.py'), 'class_name': 'NoMoneyException', 'summary': 'This source code defines a custom exception class called `NoMoneyException`, which is raised when an operation cannot be completed due to insufficient funds.\\nThe class has an initializer that takes an amount and an optional message, and sets them as attributes of the instance. \\nThe class also overrides the `__str__` method to customize the string representation of the exception instance.', 'code': 'class NoMoneyException(Exception):\\n    \"\"\"Raised when the operation cannot be completed due to insufficient funds\"\"\"\\n\\n    def __init__(self, amount, message=\"Insufficient funds\"):\\n        self.amount = amount\\n        self.message = message\\n        super().__init__(self.message)\\n\\n    def __str__(self):\\n        return f\\'{self.message} -> Amount required: {self.amount}\\'\\n'}),\n",
       " '6fffbf58-0c55-448d-9c82-07d40ebc2932': Document(page_content='Singleton Metaclass Implementation', metadata={'file_path': PosixPath('MetaGPT/metagpt/utils/singleton.py'), 'class_name': 'Singleton', 'summary': 'This source code implements a Singleton metaclass that ensures only one instance of a class exists. The metaclass uses a dictionary `_instances` to keep track of the singleton instances of each class. When a class is called, the `__call__` method is invoked, checking if an instance already exists in the dictionary and creating one if it does not.', 'code': 'class Singleton(abc.ABCMeta, type):\\n    \"\"\"\\n    Singleton metaclass for ensuring only one instance of a class.\\n    \"\"\"\\n\\n    _instances = {}\\n\\n    def __call__(cls, *args, **kwargs):\\n        \"\"\"Call method for the singleton metaclass.\"\"\"\\n        if cls not in cls._instances:\\n            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\\n        return cls._instances[cls]'}),\n",
       " '19fd6e6e-43de-4824-a75a-f247f3043618': Document(page_content='Python code for writing and saving code to a specified file location.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/write_code.py'), 'class_name': 'WriteCode', 'summary': 'This source code represents a class called `WriteCode` that is a subclass of `Action`. It includes methods for checking if a filename is invalid, saving a code file, and writing code by interactively prompting the user. The main functionality of this class is the `run` method, which generates a prompt, writes the code, and returns it.', 'code': 'class WriteCode(Action):\\n    def __init__(self, name=\"WriteCode\", context: list[Message] = None, llm=None):\\n        super().__init__(name, context, llm)\\n\\n    def _is_invalid(self, filename):\\n        return any(i in filename for i in [\"mp3\", \"wav\"])\\n\\n    def _save(self, context, filename, code):\\n        # logger.info(filename)\\n        # logger.info(code_rsp)\\n        if self._is_invalid(filename):\\n            return\\n\\n        design = [i for i in context if i.cause_by == WriteDesign][0]\\n\\n        ws_name = CodeParser.parse_str(block=\"Python package name\", text=design.content)\\n        ws_path = WORKSPACE_ROOT / ws_name\\n        if f\"{ws_name}/\" not in filename and all(i not in filename for i in [\"requirements.txt\", \".md\"]):\\n            ws_path = ws_path / ws_name\\n        code_path = ws_path / filename\\n        code_path.parent.mkdir(parents=True, exist_ok=True)\\n        code_path.write_text(code)\\n        logger.info(f\"Saving Code to {code_path}\")\\n\\n    @retry(stop=stop_after_attempt(2), wait=wait_fixed(1))\\n    async def write_code(self, prompt):\\n        code_rsp = await self._aask(prompt)\\n        code = CodeParser.parse_code(block=\"\", text=code_rsp)\\n        return code\\n\\n    async def run(self, context, filename):\\n        prompt = PROMPT_TEMPLATE.format(context=context, filename=filename)\\n        logger.info(f\\'Writing {filename}..\\')\\n        code = await self.write_code(prompt)\\n        # code_rsp = await self._aask_v1(prompt, \"code_rsp\", OUTPUT_MAPPING)\\n        # self._save(context, filename, code)\\n        return code'}),\n",
       " '2593261e-3a76-41ca-991c-306a084a48af': Document(page_content='Python class for writing test cases using the `unittest` framework', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/write_test.py'), 'class_name': 'WriteTest', 'summary': \"This source code defines a class `WriteTest` that inherits from the `Action` class. It has an `__init__` method that initializes some variables and a `run` method that takes in a `code` parameter, assigns it to `self.code`, and returns the result of calling the `_aask` method with a formatted prompt. The prompt includes the provided code and asks for test cases to be written using Python's `unittest` framework.\", 'code': 'class WriteTest(Action):\\n    def __init__(self, name=\"\", context=None, llm=None):\\n        super().__init__(name, context, llm)\\n        self.code = None\\n        self.test_prompt_template = \"\"\"\\n        Given the following code or function:\\n        {code}\\n\\n        As a test engineer, please write appropriate test cases using Python\\'s unittest framework to verify the correctness and robustness of this code.\\n        \"\"\"\\n\\n    async def run(self, code):\\n        self.code = code\\n        prompt = self.test_prompt_template.format(code=self.code)\\n        test_cases = await self._aask(prompt)\\n        return test_cases'}),\n",
       " 'aa4355b3-2f49-4708-93d9-1f918e86fa01': Document(page_content='Python code for a class that handles debugging errors in code execution.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/debug_error.py'), 'class_name': 'DebugError', 'summary': 'The given source code defines a class called `DebugError`, which is a subclass of `Action`. It has an `__init__` method that initializes the class attributes. The `run` method takes two arguments `code` and `error`, and returns a modified version of the `code`.', 'code': 'class DebugError(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n\\n    async def run(self, code, error):\\n        prompt = f\"Here is a piece of Python code:\\\\n\\\\n{code}\\\\n\\\\nThe following error occurred during execution:\" \\\\\\n                 f\"\\\\n\\\\n{error}\\\\n\\\\nPlease try to fix the error in this code.\"\\n        fixed_code = await self._aask(prompt)\\n        return fixed_code'}),\n",
       " '8e01ac52-ac75-472e-b1ed-1a7d6d132df1': Document(page_content='Python code for writing system design and saving it in a workspace.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/design_api.py'), 'class_name': 'WriteDesign', 'summary': 'This source code defines a `WriteDesign` class that inherits from the `Action` class. It contains methods for recreating a workspace, saving the PRD (Product Requirements Document) and system design, and saving the context and system design. The `run` method prompts the user to input the system design and saves it.', 'code': 'class WriteDesign(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n        self.desc = \"Based on the PRD, think about the system design, and design the corresponding APIs, \" \\\\\\n                    \"data structures, library tables, processes, and paths. Please provide your design, feedback \" \\\\\\n                    \"clearly and in detail.\"\\n\\n    def recreate_workspace(self, workspace: Path):\\n        try:\\n            shutil.rmtree(workspace)\\n        except FileNotFoundError:\\n            pass  # 文件夹不存在，但我们不在意\\n        workspace.mkdir(parents=True, exist_ok=True)\\n\\n    def _save_prd(self, docs_path, resources_path, prd):\\n        prd_file = docs_path / \\'prd.md\\'\\n        quadrant_chart = CodeParser.parse_code(block=\"Competitive Quadrant Chart\", text=prd)\\n        mermaid_to_file(quadrant_chart, resources_path / \\'competitive_analysis\\')\\n        logger.info(f\"Saving PRD to {prd_file}\")\\n        prd_file.write_text(prd)\\n\\n    def _save_system_design(self, docs_path, resources_path, content):\\n        data_api_design = CodeParser.parse_code(block=\"Data structures and interface definitions\", text=content)\\n        seq_flow = CodeParser.parse_code(block=\"Program call flow\", text=content)\\n        mermaid_to_file(data_api_design, resources_path / \\'data_api_design\\')\\n        mermaid_to_file(seq_flow, resources_path / \\'seq_flow\\')\\n        system_design_file = docs_path / \\'system_design.md\\'\\n        logger.info(f\"Saving System Designs to {system_design_file}\")\\n        system_design_file.write_text(content)\\n\\n    def _save(self, context, system_design):\\n        if isinstance(system_design, ActionOutput):\\n            content = system_design.content\\n            ws_name = CodeParser.parse_str(block=\"Python package name\", text=content)\\n        else:\\n            content = system_design\\n            ws_name = CodeParser.parse_str(block=\"Python package name\", text=system_design)\\n        workspace = WORKSPACE_ROOT / ws_name\\n        self.recreate_workspace(workspace)\\n        docs_path = workspace / \\'docs\\'\\n        resources_path = workspace / \\'resources\\'\\n        docs_path.mkdir(parents=True, exist_ok=True)\\n        resources_path.mkdir(parents=True, exist_ok=True)\\n        self._save_prd(docs_path, resources_path, context[-1].content)\\n        self._save_system_design(docs_path, resources_path, content)\\n\\n    async def run(self, context):\\n        prompt = PROMPT_TEMPLATE.format(context=context, format_example=FORMAT_EXAMPLE)\\n        # system_design = await self._aask(prompt)\\n        system_design = await self._aask_v1(prompt, \"system_design\", OUTPUT_MAPPING)\\n        self._save(context, system_design)\\n        return system_design'}),\n",
       " '395b74e9-691e-4de8-9c02-48797998ba46': Document(page_content='Python class with methods for creating model classes and performing validation checks.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/action_output.py'), 'class_name': 'ActionOutput', 'summary': 'This source code defines a class called `ActionOutput` that has two attributes: `content` of type string and `instruct_content` of type `BaseModel`. It also provides a class method called `create_model_class` that creates a new class dynamically using the `create_model` function from the `pydantic` library. The dynamically created class includes two validators: `check_name`, which checks if the given field name is recognized, and `check_missing_fields`, which checks if all required fields are present.', 'code': \"class ActionOutput:\\n    content: str\\n    instruct_content: BaseModel\\n\\n    def __init__(self, content: str, instruct_content: BaseModel):\\n        self.content = content\\n        self.instruct_content = instruct_content\\n\\n    @classmethod\\n    def create_model_class(cls, class_name: str, mapping: Dict[str, Type]):\\n        new_class = create_model(class_name, **mapping)\\n\\n        @validator('*', allow_reuse=True)\\n        def check_name(v, field):\\n            if field.name not in mapping.keys():\\n                raise ValueError(f'Unrecognized block: {field.name}')\\n            return v\\n\\n        @root_validator(pre=True, allow_reuse=True)\\n        def check_missing_fields(values):\\n            required_fields = set(mapping.keys())\\n            missing_fields = required_fields - set(values.keys())\\n            if missing_fields:\\n                raise ValueError(f'Missing fields: {missing_fields}')\\n            return values\\n\\n        new_class.__validator_check_name = classmethod(check_name)\\n        new_class.__root_validator_check_missing_fields = classmethod(check_missing_fields)\\n        return new_class\"}),\n",
       " 'e848b914-2c9a-498a-98ef-a4a9cdc5c546': Document(page_content='Python class for a boss requirement without implementation details', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/add_requirement.py'), 'class_name': 'BossRequirement', 'summary': 'The code defines a class called `BossRequirement` that inherits from `Action`. The `run` method of this class raises a `NotImplementedError`, indicating that it is meant to be overridden with a specific implementation. The class also has a docstring that provides a brief description of its purpose.', 'code': 'class BossRequirement(Action):\\n    \"\"\"Boss Requirement without any implementation details\"\"\"\\n    async def run(self, *args, **kwargs):\\n        raise NotImplementedError'}),\n",
       " '180a9735-601f-4eba-b998-326c21d06520': Document(page_content='Enum Definition for ActionType', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/__init__.py'), 'class_name': 'ActionType', 'summary': 'The code defines an enumeration called ActionType, which represents different types of actions. Each action type is associated with a specific class. The enumeration includes various action types such as adding a requirement, writing a PRD, writing a design, and so on.', 'code': 'class ActionType(Enum):\\n    \"\"\"All types of Actions, used for indexing.\"\"\"\\n    ADD_REQUIREMENT = BossRequirement\\n    WRITE_PRD = WritePRD\\n    WRITE_PRD_REVIEW = WritePRDReview\\n    WRITE_DESIGN = WriteDesign\\n    DESIGN_REVIEW = DesignReview\\n    DESIGN_FILENAMES = DesignFilenames\\n    WRTIE_CODE = WriteCode\\n    WRITE_CODE_REVIEW = WriteCodeReview\\n    WRITE_TEST = WriteTest\\n    RUN_CODE = RunCode\\n    DEBUG_ERROR = DebugError\\n    WRITE_TASKS = WriteTasks\\n    ASSIGN_TASKS = AssignTasks\\n    SEARCH_AND_SUMMARIZE = SearchAndSummarize'}),\n",
       " 'e512206c-3c77-482e-8e9b-97c0458b75eb': Document(page_content='Python class implementing an abstract action with various methods.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/action.py'), 'class_name': 'Action', 'summary': 'The given source code defines a base class called `Action` that represents an abstract action. It has various attributes and methods, such as `name`, `context`, and `set_prefix()`. The class also includes methods like `_aask()` and `_aask_v1()` for handling prompts and returning the results. Lastly, the class has a `run()` method that raises a `NotImplementedError` and should be implemented in subclasses.', 'code': 'class Action(ABC):\\n    def __init__(self, name: str = \\'\\', context=None, llm: LLM = None):\\n        self.name: str = name\\n        if llm is None:\\n            llm = LLM()\\n        self.llm = llm\\n        self.context = context\\n        self.prefix = \"\"\\n        self.profile = \"\"\\n        self.desc = \"\"\\n        self.content = \"\"\\n        self.instruct_content = None\\n\\n    def set_prefix(self, prefix, profile):\\n        \"\"\"Set prefix for later usage\"\"\"\\n        self.prefix = prefix\\n        self.profile = profile\\n\\n    def __str__(self):\\n        return self.__class__.__name__\\n\\n    def __repr__(self):\\n        return self.__str__()\\n\\n    async def _aask(self, prompt: str, system_msgs: Optional[list[str]] = None) -> str:\\n        \"\"\"Append default prefix\"\"\"\\n        if not system_msgs:\\n            system_msgs = []\\n        system_msgs.append(self.prefix)\\n        return await self.llm.aask(prompt, system_msgs)\\n\\n    @retry(stop=stop_after_attempt(2), wait=wait_fixed(1))\\n    async def _aask_v1(self, prompt: str, output_class_name: str,\\n                       output_data_mapping: dict,\\n                       system_msgs: Optional[list[str]] = None) -> ActionOutput:\\n        \"\"\"Append default prefix\"\"\"\\n        if not system_msgs:\\n            system_msgs = []\\n        system_msgs.append(self.prefix)\\n        content = await self.llm.aask(prompt, system_msgs)\\n        logger.debug(content)\\n        output_class = ActionOutput.create_model_class(output_class_name, output_data_mapping)\\n        parsed_data = OutputParser.parse_data_with_mapping(content, output_data_mapping)\\n        logger.debug(parsed_data)\\n        instruct_content = output_class(**parsed_data)\\n        return ActionOutput(content, instruct_content)\\n\\n    async def run(self, *args, **kwargs):\\n        \"\"\"Run action\"\"\"\\n        raise NotImplementedError(\"The run method should be implemented in a subclass.\")'}),\n",
       " 'eb5b2196-99f8-4443-9455-459496278519': Document(page_content='Python code for writing a PRD (Product Requirement Document) based on search results and search summary.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/write_prd.py'), 'class_name': 'WritePRD', 'summary': 'This source code defines a class called `WritePRD` that inherits from the `Action` class. It has an asynchronous `run` method that takes requirements as input and returns an `ActionOutput`. The method calls the `SearchAndSummarize` class to search and summarize information, and then generates a prompt using the search results. Finally, it uses a `_aask_v1` method to interact with a service and return the result.', 'code': 'class WritePRD(Action):\\n    def __init__(self, name=\"\", context=None, llm=None):\\n        super().__init__(name, context, llm)\\n\\n    async def run(self, requirements, *args, **kwargs) -> ActionOutput:\\n        sas = SearchAndSummarize()\\n        # rsp = await sas.run(context=requirements, system_text=SEARCH_AND_SUMMARIZE_SYSTEM_EN_US)\\n        rsp = \"\"\\n        info = f\"### Search Results\\\\n{sas.result}\\\\n\\\\n### Search Summary\\\\n{rsp}\"\\n        if sas.result:\\n            logger.info(sas.result)\\n            logger.info(rsp)\\n\\n        prompt = PROMPT_TEMPLATE.format(requirements=requirements, search_information=info,\\n                                        format_example=FORMAT_EXAMPLE)\\n        logger.debug(prompt)\\n        prd = await self._aask_v1(prompt, \"prd\", OUTPUT_MAPPING)\\n        return prd'}),\n",
       " 'a94c7704-9d9b-4a69-99f7-2b95c49ecd6e': Document(page_content='Azure Text-to-Speech (TTS) Synthesis', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/azure_tts.py'), 'class_name': 'AzureTTS', 'summary': 'The given source code is a class named \"AzureTTS\" that inherits from the \"Action\" class. It contains a method called \"synthesize_speech\" which takes in parameters such as language, voice, role, text, and output file. The method utilizes the Azure Cognitive Services Speech Service to synthesize speech based on the provided parameters and saves the output as an audio file.', 'code': 'class AzureTTS(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n        self.config = Config()\\n\\n    # 参数参考：https://learn.microsoft.com/zh-cn/azure/cognitive-services/speech-service/language-support?tabs=tts#voice-styles-and-roles\\n    def synthesize_speech(self, lang, voice, role, text, output_file):\\n        subscription_key = self.config.get(\\'AZURE_TTS_SUBSCRIPTION_KEY\\')\\n        region = self.config.get(\\'AZURE_TTS_REGION\\')\\n        speech_config = SpeechConfig(\\n            subscription=subscription_key, region=region)\\n\\n        speech_config.speech_synthesis_voice_name = voice\\n        audio_config = AudioConfig(filename=output_file)\\n        synthesizer = SpeechSynthesizer(\\n            speech_config=speech_config,\\n            audio_config=audio_config)\\n\\n        # if voice==\"zh-CN-YunxiNeural\":\\n        ssml_string = f\"\"\"\\n            <speak version=\\'1.0\\' xmlns=\\'http://www.w3.org/2001/10/synthesis\\' xml:lang=\\'{lang}\\' xmlns:mstts=\\'http://www.w3.org/2001/mstts\\'>\\n                <voice name=\\'{voice}\\'>\\n                    <mstts:express-as style=\\'affectionate\\' role=\\'{role}\\'>\\n                        {text}\\n                    </mstts:express-as>\\n                </voice>\\n            </speak>\\n            \"\"\"\\n\\n        synthesizer.speak_ssml_async(ssml_string).get()\\n'}),\n",
       " '7fe93e5d-acd5-4f8a-a2f9-05ae0a771b23': Document(page_content='Python class for running code and capturing the result', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/run_code.py'), 'class_name': 'RunCode', 'summary': 'This code defines a class called `RunCode` which inherits from `Action`. It has an asynchronous `run` method that takes a `code` parameter and executes it within a defined `namespace` dictionary. If the code executes successfully, it returns the value of the `result` key in the namespace. If there is an error, it returns the formatted traceback message.', 'code': \"class RunCode(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n\\n    async def run(self, code):\\n        try:\\n            # We will document_store the result in this dictionary\\n            namespace = {}\\n            exec(code, namespace)\\n            return namespace.get('result', None)\\n        except Exception:\\n            # If there is an error in the code, return the error message\\n            return traceback.format_exc()\"}),\n",
       " '074661bf-0f12-4eef-9800-ab7d2a326f5c': Document(page_content='WritePRDReview class for conducting a PRD review and providing feedback.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/write_prd_review.py'), 'class_name': 'WritePRDReview', 'summary': 'This source code defines a class called `WritePRDReview` that inherits from an `Action` class. It has an `__init__` method that initializes some attributes, including a PRD description. The `run` method accepts a PRD as an argument, sets it to the class attribute, prompts the user for a review using the `aask` method, and returns the review.', 'code': 'class WritePRDReview(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n        self.prd = None\\n        self.desc = \"Based on the PRD, conduct a PRD Review, providing clear and detailed feedback\"\\n        self.prd_review_prompt_template = \"\"\"\\n        Given the following Product Requirement Document (PRD):\\n        {prd}\\n\\n        As a project manager, please review it and provide your feedback and suggestions.\\n        \"\"\"\\n\\n    async def run(self, prd):\\n        self.prd = prd\\n        prompt = self.prd_review_prompt_template.format(prd=self.prd)\\n        review = await self._aask(prompt)\\n        return review'}),\n",
       " 'f8e834bb-4a81-417c-b733-1b21e231bd68': Document(page_content='Class for searching and summarizing information using a search engine.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/search_and_summarize.py'), 'class_name': 'SearchAndSummarize', 'summary': 'This source code defines a `SearchAndSummarize` class with an `async run` method, which takes a list of messages and a system text as input and returns a string. It initializes various variables and checks for API key configurations. It then makes a search query using the SearchEngine class, stores the response, and prompts the user for input using a formatted string before returning the result.', 'code': 'class SearchAndSummarize(Action):\\n    def __init__(self, name=\"\", context=None, llm=None, engine=None, search_func=None):\\n        self.config = Config()\\n        self.engine = engine or self.config.search_engine\\n        self.search_engine = SearchEngine(self.engine, run_func=search_func)\\n        self.result = \"\"\\n        super().__init__(name, context, llm)\\n\\n    async def run(self, context: list[Message], system_text=SEARCH_AND_SUMMARIZE_SYSTEM) -> str:\\n        no_serpapi = not self.config.serpapi_api_key or \\'YOUR_API_KEY\\' == self.config.serpapi_api_key\\n        no_serper = not self.config.serper_api_key or \\'YOUR_API_KEY\\' == self.config.serper_api_key\\n        no_google = not self.config.google_api_key or \\'YOUR_API_KEY\\' == self.config.google_api_key\\n        \\n        if no_serpapi and no_google and no_serper:\\n            logger.warning(\\'Configure one of SERPAPI_API_KEY, SERPER_API_KEY, GOOGLE_API_KEY to unlock full feature\\')\\n            return \"\"\\n        \\n        query = context[-1].content\\n        # logger.debug(query)\\n        rsp = await self.search_engine.run(query)\\n        self.result = rsp\\n        if not rsp:\\n            logger.error(\\'empty rsp...\\')\\n            return \"\"\\n        # logger.info(rsp)\\n\\n        system_prompt = [system_text]\\n\\n        prompt = SEARCH_AND_SUMMARIZE_PROMPT.format(\\n            # PREFIX = self.prefix,\\n            ROLE=self.profile,\\n            CONTEXT=rsp,\\n            QUERY_HISTORY=\\'\\\\n\\'.join([str(i) for i in context[:-1]]),\\n            QUERY=str(context[-1])\\n        )\\n        result = await self._aask(prompt, system_prompt)\\n        logger.debug(prompt)\\n        logger.debug(result)\\n        return result'}),\n",
       " '59ea0afe-4290-46ab-bb1a-a175d6e2ae5e': Document(page_content='Python class for writing code reviews', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/write_code_review.py'), 'class_name': 'WriteCodeReview', 'summary': 'This source code defines a class `WriteCodeReview` that inherits from `Action`. It has an `__init__` method that initializes some variables, as well as a `write_code` method that uses the `@retry` decorator to retry the code writing process in case of failure. Finally, there is a `run` method that takes in some parameters, formats a prompt, writes code using the `write_code` method, and returns the code.', 'code': 'class WriteCodeReview(Action):\\n    def __init__(self, name=\"WriteCodeReview\", context: list[Message] = None, llm=None):\\n        super().__init__(name, context, llm)\\n\\n    @retry(stop=stop_after_attempt(2), wait=wait_fixed(1))\\n    async def write_code(self, prompt):\\n        code_rsp = await self._aask(prompt)\\n        code = CodeParser.parse_code(block=\"\", text=code_rsp)\\n        return code\\n\\n    async def run(self, context, code, filename):\\n        format_example = FORMAT_EXAMPLE.format(filename=filename)\\n        prompt = PROMPT_TEMPLATE.format(context=context, code=code, filename=filename, format_example=format_example)\\n        logger.info(f\\'Code review {filename}..\\')\\n        code = await self.write_code(prompt)\\n        # code_rsp = await self._aask_v1(prompt, \"code_rsp\", OUTPUT_MAPPING)\\n        # self._save(context, filename, code)\\n        return code'}),\n",
       " '799436e3-5134-4f41-bf7b-bc1837efdf9c': Document(page_content='Python class for writing tasks and saving data to files', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/project_management.py'), 'class_name': 'WriteTasks', 'summary': 'The given source code defines a class named \"WriteTasks\" which is a subclass of \"Action\". It has methods to save data to files and run tasks asynchronously. The \"run\" method prompts for input, saves the response data to files, and returns the response.', 'code': 'class WriteTasks(Action):\\n\\n    def __init__(self, name=\"CreateTasks\", context=None, llm=None):\\n        super().__init__(name, context, llm)\\n\\n    def _save(self, context, rsp):\\n        ws_name = CodeParser.parse_str(block=\"Python package name\", text=context[-1].content)\\n        file_path = WORKSPACE_ROOT / ws_name / \\'docs/api_spec_and_tasks.md\\'\\n        file_path.write_text(rsp.content)\\n\\n        # Write requirements.txt\\n        requirements_path = WORKSPACE_ROOT / ws_name / \\'requirements.txt\\'\\n        requirements_path.write_text(rsp.instruct_content.dict().get(\"Required Python third-party packages\").strip(\\'\"\\\\n\\'))\\n\\n    async def run(self, context):\\n        prompt = PROMPT_TEMPLATE.format(context=context, format_example=FORMAT_EXAMPLE)\\n        rsp = await self._aask_v1(prompt, \"task\", OUTPUT_MAPPING)\\n        self._save(context, rsp)\\n        return rsp\\n'}),\n",
       " 'feb1b84a-f228-4386-81b4-ae4c589c185b': Document(page_content='Asynchronous action function in a class.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/project_management.py'), 'class_name': 'AssignTasks', 'summary': 'This is a Python class called `AssignTasks` that extends `Action`. It has an `async` method called `run` which is used to implement the main logic of the action. However, the current implementation of the `run` method is empty.', 'code': 'class AssignTasks(Action):\\n    async def run(self, *args, **kwargs):\\n        # Here you should implement the actual action\\n        pass'}),\n",
       " '819f5ced-1acc-47f2-b020-4a6ea3b9da81': Document(page_content='Class for designing filenames based on Product Requirement Document (PRD) and carrying out basic design of APIs, data structures, and database tables.', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/design_filenames.py'), 'class_name': 'DesignFilenames', 'summary': 'This source code defines a class called `DesignFilenames` which inherits from the `Action` class. It has an `__init__` method that initializes the object with a description and a `run` method that takes a Product Requirement Document (PRD) as input, presents it to the user and returns the design filenames obtained from user input. The class also has a private method `_aask` which is not shown in the code snippet.', 'code': 'class DesignFilenames(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n        self.desc = \"Based on the PRD, consider system design, and carry out the basic design of the corresponding \" \\\\\\n                    \"APIs, data structures, and database tables. Please give your design, feedback clearly and in detail.\"\\n\\n    async def run(self, prd):\\n        prompt = f\"The following is the Product Requirement Document (PRD):\\\\n\\\\n{prd}\\\\n\\\\n{PROMPT}\"\\n        design_filenames = await self._aask(prompt)\\n        logger.debug(prompt)\\n        logger.debug(design_filenames)\\n        return design_filenames'}),\n",
       " 'eff8663d-0145-4fa6-a4a8-2a2025dea732': Document(page_content='AnalyzeDepLibs class with run method for analyzing program dependencies', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/analyze_dep_libs.py'), 'class_name': 'AnalyzeDepLibs', 'summary': \"This source code defines a class called `AnalyzeDepLibs` that inherits from the `Action` class. The `run` method of this class takes in two parameters and returns a list of design filenames. The purpose of this class is to analyze the program's runtime dependencies based on the given requirement and file paths.\", 'code': 'class AnalyzeDepLibs(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n        self.desc = \"根据上下文，分析程序运行依赖库\"\\n\\n    async def run(self, requirement, filepaths_string):\\n        # prompt = f\"以下是产品需求文档(PRD):\\\\n\\\\n{prd}\\\\n\\\\n{PROMPT}\"\\n        prompt = PROMPT.format(prompt=requirement, filepaths_string=filepaths_string)\\n        design_filenames = await self._aask(prompt)\\n        return design_filenames'}),\n",
       " '4e689610-03ff-4bc9-ab73-e60a660e23c4': Document(page_content='Class for conducting a design review of an API based on a Product Requirement Document (PRD)', metadata={'file_path': PosixPath('MetaGPT/metagpt/actions/design_api_review.py'), 'class_name': 'DesignReview', 'summary': \"This code defines a class called `DesignReview` which inherits from the `Action` class. It has an `__init__` method that calls the parent class's `__init__` method. The `run` method takes two arguments, `prd` and `api_design`, and prompts the user to review the API design based on the given PRD. It then asks the user to provide their review comments and returns them.\", 'code': 'class DesignReview(Action):\\n    def __init__(self, name, context=None, llm=None):\\n        super().__init__(name, context, llm)\\n\\n    async def run(self, prd, api_design):\\n        prompt = f\"Here is the Product Requirement Document (PRD):\\\\n\\\\n{prd}\\\\n\\\\nHere is the list of APIs designed \" \\\\\\n                 f\"based on this PRD:\\\\n\\\\n{api_design}\\\\n\\\\nPlease review whether this API design meets the requirements\" \\\\\\n                 f\" of the PRD, and whether it complies with good design practices.\"\\n\\n        api_review = await self._aask(prompt)\\n        return api_review'})}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
